<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>哦豁</title>
    <link href="/2023/03/01/ohuo/"/>
    <url>/2023/03/01/ohuo/</url>
    
    <content type="html"><![CDATA[<p>这几天的访问量和访问人数不太对劲，显然是有人在看这个博客，竟然有人能看到这个博客哈哈哈，你会是谁呢？</p><p>欢迎联系我 : )</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>鹤山之行</title>
    <link href="/2023/02/27/HeshanTour/"/>
    <url>/2023/02/27/HeshanTour/</url>
    
    <content type="html"><![CDATA[<p>前排提醒，此游记为小学生日记类型的流水账 : )</p><p>从好久之前就说周末要出去走走，不能一直窝在宿舍（or 实验室）里，但一直因为各种原因没有实现。这个学期刚开学课业压力不大，又正好这个周末大家都没什么安排，于是就约好一块出去玩了。</p><p>虽然来青岛校区已经一年半了，但这还是第一次因为要去附近的景点游玩而出来（之前要么是因为聚餐要么是去轰趴狼人杀这一类的），大家都没什么经验，于是就定了个最近的（是景区的）山，即鹤山（距学校只有10分钟车程）。</p><p>山不大，感觉一会儿就全走遍了，令人印象比较深刻的景点也不多，大概只有滚龙洞一个（大概就是巨石堆砌留下了紧贴地面的一道缝隙，匍匐前进方可通过）。但一路欢声笑语（这个词用的感觉像小学生游记，乐），玩的也是十分开心，站在山崖边的巨石上，山下风景一览无余，耳畔回荡着大家的互相打趣，要是有时刻相机能记录此时就好了。可能这样的场景并不罕见，但于我们（至少于我）确实是一次珍贵的回忆了，毕竟也是第一次寝室旅行类团建（泰山那次阿旭没去）。</p><p>下山后我们打车去西门的一家好像叫什么鑫城饺子馆的餐厅吃饭，路上还发生了一段小插曲，大概就是我下车时忘带手机了（手机在用司机师傅数据线充电），然后司机师傅后来给我送了回来，送回来时我还没发现，当时光顾着跟鸣谦拉呱了……吃的不错，这家店做的菜味道确实可以，尤其那个茼蒿小豆腐，是滴真香啊~</p><p>唉，这体验感不比在宿舍窝着好多了，以后要多多出来走走。</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>游记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客恢复更新</title>
    <link href="/2023/02/22/restart/"/>
    <url>/2023/02/22/restart/</url>
    
    <content type="html"><![CDATA[<p>大年初五那天发现提交博客时 git 出问题，当时调了一会儿没调好就没再弄（因为那会儿正好要去看电影），然后就是准备开学考试，也就一直没来得及修。</p><p>上周考试一直考到周日，考完以后好好休息了两天，今天才抽时间弄了下。颇是费了一番功夫，不过也好歹是把问题给解决了（就只是 ssh 密钥的问题，竟然找这么久，离谱），博客成功恢复更新！</p><p>太晚了先睡觉了，明天起床把这段时间没上传的都补一下（</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>终于考完了</title>
    <link href="/2023/02/20/230220/"/>
    <url>/2023/02/20/230220/</url>
    
    <content type="html"><![CDATA[<p>魔鬼考试周终于过去了（六天考六门真的折磨，再也不想经历一次了），今天休息一天，明天开始去实验室打工。</p><p><img src="/2023/02/20/230220/image-20230222102357025.png" alt="考试周安排(蓝色为计划的复习时间段，红色为考试时间段)"></p><p>晚上重新看了一遍星际穿越，真是艺术品啊……唉，想写些影评，但可惜我辞藻匮乏，纯纯文化沙漠，怕写出来的影评配不上这样的好电影 : ( 。不过总之电影超级好看就完事了，之前看过好多次，但这次还是看的津津有味~</p><p>本科生院崩了，没法查成绩，不知道这次会怎么样，感觉发挥的还不错，但会不会又跟之前一样只是自以为考得不错结果出成绩低的可笑呢？还是怪自己考前复习不足吧……</p><p>明天实验室冲冲冲！</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自省</title>
    <link href="/2023/02/04/230204/"/>
    <url>/2023/02/04/230204/</url>
    
    <content type="html"><![CDATA[<p>今天看到一句话，颇有感触，记录于此。</p><p>“你不用变得很外向，内向挺好的，但需要你发言的时候，一定要勇敢。正所谓：君子可内敛不可懦弱。”</p><p>所以说一定要克服在当众发言时声音变得很小的心理障碍啊，找回曾经那个敢于在讲台上勇敢发言的自己。</p><p>（“君子可内敛不可懦弱”后面还有一句“面不公可起而论之”，但感觉语境跟这里不符就去掉了）</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论大年初一被安排任务</title>
    <link href="/2023/01/22/230122/"/>
    <url>/2023/01/22/230122/</url>
    
    <content type="html"><![CDATA[<p>早就听说汪老师春节期间都会忙于工作，今天见识到了。</p><p><img src="/2023/01/22/230122/image-20230122234016064.png" alt="image-20230122234016064"></p><p>虽然导致了我春节一晚上都坐电脑前，但这种对工作的热情还真挺打动（or 惊讶）人的。</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>开组会有感</title>
    <link href="/2023/01/20/230120/"/>
    <url>/2023/01/20/230120/</url>
    
    <content type="html"><![CDATA[<p>开完组会只觉得，唉，我好废啊，为什么没有准备得再认真些呢……会上汪老师问了几句后我也就能想清楚了，明明也没多难啊，可当时怎么就没有再对模型深究一下？</p><p>结果在年前的最后一天还耽误了大家很多时间。</p><p>还给大家留下了坏印象。</p><p>不过说来也是，这种被当众批评的感觉，也算是一种激励吧。</p><p>（感觉汪老师有点像老段</p><p>次日小记（就不单独开一篇了）：</p><p>唉，昨晚开完组会很低落，跟路哥聊了会，感觉更愧疚了，但除夕到了，盼了许久的年限皮肤上架了，也算是一种调和吧。可用新皮肤跟朋友打了打娱乐准备睡时，发现邮箱里的已读邮件有两个带着”惩罚“”提醒“的字眼，点开发现号被禁赛了。这半年基本没玩，号一直给他们借着玩，倒也被检测过几次，但知秋借一直没啥问题，万万没想到除夕给我封了。哈哈，得，调和由正变负了。</p><p>想了想，其实这种用游戏来调和的方式可能正是我上大学后不再优秀的原因吧。之前心情低落时，会用看书啊、听歌啊甚至是做题的方式来调和，静心的同时，很多事情也就想明白了。而现在遇到不顺利的事的时候，可能就只会选择玩会游戏或者看会 b 站，情绪很快就调节好了，但那些不顺利的事也随之被置于脑后，不再细想了，于是下次可能继续出现类似问题，然后类似的，又会被娱乐化活动迅速调节。这种对不顺利的事的思考的过程，正是提升自己的重要过程，每次都不对错误进行总结反思，渐渐地，就落下了。</p><p>哈哈，确实也是啊，如果快乐都是娱乐活动给的，失落都是学业、实验任务等给的，何谈能对学习有热情呢？要找回之前那种从提升自己中获得满足感的节奏啊。</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Code LMs</title>
    <link href="/2023/01/20/codeLMs/"/>
    <url>/2023/01/20/codeLMs/</url>
    
    <content type="html"><![CDATA[<h2 id="CodeX"><a href="#CodeX" class="headerlink" title="CodeX"></a>CodeX</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>在 GPT 模型基础上，使用 Github 上的代码做了微调。</p><p>（GPT-3 的卖点确实是不需要微调→为了模型创新性，但这里属于应用创新性，所以微调也无妨。</p><p>本质：GPT 在新的数据集上训练，得到新的应用。</p><h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p><img src="/2023/01/20/codeLMs/image-20230119133213886.png" alt="image-20230119133213886"></p><p>生成一个答案：28.8%；跑一百遍，利用单元测试（文档+单元测试的人工工作量过大，不现实）得出最优解：77.5%；100次运行+利用给出的排序算法自动给出最优解：44.5%。</p><p>模型↑，准确率↑。</p><h4 id="验证集"><a href="#验证集" class="headerlink" title="验证集"></a>验证集</h4><p>human-eval: 164个编程问题，如算法问题、简单的数学问题、软件面试问题等。</p><p><img src="/2023/01/20/codeLMs/image-20230119212019266.png" alt="image-20230119212019266"></p><p>164个问题，每个问题都提供了函数的签名、文档、实现和多个单元测试（平均每个问题7.7个）。</p><p>均为手动实现→防止代码已出现在训练集中。</p><h3 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h3><h4 id="评估框架"><a href="#评估框架" class="headerlink" title="评估框架"></a>评估框架</h4><h5 id="正确性的评估"><a href="#正确性的评估" class="headerlink" title="正确性的评估"></a>正确性的评估</h5><h6 id="往往采用"><a href="#往往采用" class="headerlink" title="往往采用"></a>往往采用</h6><p>BLEU score：生成序列与真正的标号序列在一些子序列上的相似度，是一种模糊的匹配。BLEU score无法胜任代码匹配的评估上。</p><h6 id="该模型采用"><a href="#该模型采用" class="headerlink" title="该模型采用"></a>该模型采用</h6><p>pass@k metric: k 表示可以生成 k 个不同结果，有一个正确就视为正确。</p><h6 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h6><p>生成 n (n&gt;k) 个样本，然后每次从里面随机采 k 个出来（因为重复生成 k 个样本太贵了），看是否有正确答案。</p><p><img src="/2023/01/20/codeLMs/image-20230119162657083.png" alt="image-20230119162657083"></p><p>E 表示对164个值求平均，c 表示正确个数。</p><p>（公式虽然简单，但数很大时，计算量过大，这里采取了一定处理避免超限（把组合数化简）。</p><h6 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h6><p>k较大时，结果会过于乐观；结果的排序很重要，但这里无法对排序进行评估。</p><p>后续会讨论。</p><h5 id="验证集-1"><a href="#验证集-1" class="headerlink" title="验证集"></a>验证集</h5><h5 id="运行代码的沙盒"><a href="#运行代码的沙盒" class="headerlink" title="运行代码的沙盒"></a>运行代码的沙盒</h5><p>类似虚拟机。</p><p>防止恶意代码影响机器。</p><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><h5 id="数据的收集"><a href="#数据的收集" class="headerlink" title="数据的收集"></a>数据的收集</h5><p>179 GB python 文件，清洗得到 159 GB。</p><p>问题：没有关注代码的开源协议。</p><h5 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h5><p>从 GPT-3 微调→精度上竟然没有提升（可能是因为微调的数据集过大），但收敛速度快，也就这样做下去了。</p><h5 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h5><h6 id="空格"><a href="#空格" class="headerlink" title="空格"></a>空格</h6><p>代码中词的分布与自然语言中词的分布有很大区别，所以 GPT-3 的分词器在表示代码时不够有效。效率低下的一个主要原因是空格的编码，因此这里在 GPT-3 的分词器的基础上加入了额外的一系列 tokens用来表示不同长度的空格，这样在表示代码时可以少使用30%的token。</p><h6 id="停止符"><a href="#停止符" class="headerlink" title="停止符"></a>停止符</h6><p>生成答案时，遇到 ”\nclass“, ”\ndef“, ”\n#“, ”\nif“, or ”\nprint“ 时停止。</p><h6 id="核采样"><a href="#核采样" class="headerlink" title="核采样"></a>核采样</h6><ol><li>一般采样：每次做序列生成时，将当前序列放进模型，得到当前最好的单词，但：无法保证全局最优；每次得到的输出都确定，无论运行多少遍得到的结果都相同。</li><li>改进：Beam Search（束搜索），维护32个或128个当前最好的候选。</li><li>核采样：构造一个最小候选集，使得：$$\sum_{x \in V} P(x)&gt;p$$ （文章中 p 取了0.95），然后重新归一化集合内词的概率，作为候选集。</li></ol><p>优点：保证了结果多样性的同时过滤掉了特别不靠谱的词。</p><h4 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h4><h5 id="模型大小与测试损失的关系"><a href="#模型大小与测试损失的关系" class="headerlink" title="模型大小与测试损失的关系"></a>模型大小与测试损失的关系</h5><p><img src="/2023/01/20/codeLMs/image-20230119212722494.png" alt="image-20230119212722494"></p><h5 id="不同-Temperature-下，样本数量与-pass-k-的关系"><a href="#不同-Temperature-下，样本数量与-pass-k-的关系" class="headerlink" title="不同 Temperature 下，样本数量与 pass@k 的关系"></a>不同 Temperature 下，样本数量与 pass@k 的关系</h5><p><img src="/2023/01/20/codeLMs/image-20230119213418011.png" alt="image-20230119213418011"></p><p>Temperature：将单词数列输出除以 temperature，达到调和概率值的目的。</p><p>样本数量较大时，温度越高效果越好→这可能是由于样本多样性的增加。</p><h5 id="不同样本数量下的最佳-Temperature"><a href="#不同样本数量下的最佳-Temperature" class="headerlink" title="不同样本数量下的最佳 Temperature"></a>不同样本数量下的最佳 Temperature</h5><p><img src="/2023/01/20/codeLMs/image-20230119214821833.png" alt="image-20230119214821833"></p><h5 id="排序算法的比较"><a href="#排序算法的比较" class="headerlink" title="排序算法的比较"></a>排序算法的比较</h5><p><img src="/2023/01/20/codeLMs/image-20230119215407301.png" alt="image-20230119215407301"></p><p>Oracle：在单元测试上测完后再排序得到结果，现实实现不现实。</p><p>Mean logp：把每个解中的候选词在 softmax 上的概率作 log 运算后再求均值，将均值最高的解作为结果。</p><h5 id="用-BLEU-score-对正确-x2F-错误的解决方案进行打分"><a href="#用-BLEU-score-对正确-x2F-错误的解决方案进行打分" class="headerlink" title="用 BLEU score 对正确&#x2F;错误的解决方案进行打分"></a>用 BLEU score 对正确&#x2F;错误的解决方案进行打分</h5><p><img src="/2023/01/20/codeLMs/image-20230119220636853.png" alt="image-20230119220636853"></p><p>发现其很难正确区分解决方案是正确的还是错误的。</p><h5 id="CodeX-S"><a href="#CodeX-S" class="headerlink" title="CodeX-S"></a>CodeX-S</h5><p><img src="/2023/01/20/codeLMs/image-20230120110246895.png" alt="image-20230120110246895"></p><p><img src="/2023/01/20/codeLMs/image-20230120110346153.png" alt="image-20230120110346153"></p><h4 id="CodeX-S-1"><a href="#CodeX-S-1" class="headerlink" title="CodeX-S"></a>CodeX-S</h4><h5 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h5><p>训练集为 Github 上爬下来的代码，评估是根据一些写好的注释来预测实现，二者形式不统一。</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>收集了新的数据集（Supervised Fine-Tuning 数据集），该数据集与评估集形式相近。</p><p>在新数据集上微调得到 CodeX-S。</p><h5 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h5><p>只生成一个答案：28.8%→37.7%。</p><h4 id="CodeX-D"><a href="#CodeX-D" class="headerlink" title="CodeX-D"></a>CodeX-D</h4><p>函数实现→实验文档。</p><h5 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h5><p>调整了训练集数据的顺序，将注释放到最后。</p><h5 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h5><ol><li>人眼看；</li><li>先用CodeX-D生成文档，再用文档和函数签名生成函数实现，看结果能否过单元测试。</li></ol><p><img src="/2023/01/20/codeLMs/image-20230120111612158.png" alt="image-20230120111612158"></p><h4 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h4><ul><li><p>样本有效性不够，需要看很多代码才能写比较简单的代码。</p></li><li><p>docstrings 的书写规范。定义了多个测试单元，发现链接的单元越多（docstrings 越长），通过率越低（指数级下降）。</p><p><img src="/2023/01/20/codeLMs/image-20230120111857932.png" alt="image-20230120111857932"></p></li><li><p>处理数学问题的能力较差。</p><p><img src="/2023/01/20/codeLMs/image-20230120112147169.png" alt="image-20230120112147169"></p></li></ul><h4 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h4><ul><li>bug</li><li>Github 男性用户居多→性别歧视问题</li><li>替代人工的社会性问题</li><li>恶意使用</li><li>……</li></ul><h2 id="PolyCoder"><a href="#PolyCoder" class="headerlink" title="PolyCoder"></a>PolyCoder</h2><p>在代码上训练的语言模型越来越多，考虑到这些模型中涉及的模型大小和训练方案的多样性，以及这些模型之间缺乏比较，许多建模和训练设计决策的影响仍不清楚。本文对现有的跨各种编程语言的代码模型——Codex、GPT-J、GPT-Neo、GPT-NeoX和CodeParrot——进行了系统评估并发布了PolyCoder模型，该模型基于 GPT-2 架构并在12种编程语言上进行预训练。</p><p><img src="/2023/01/20/codeLMs/image-20230120112947452.png" alt="image-20230120112947452"></p><p>PPL结果如图6所示，PolyCoder在C语言中优于Codex和所有其他模型。仅比较开源模型，PolyCoder在C、JavaScript、Rust、Scala和TypeScript中的性能要优于类似大小的GPT-Neo 2.7B。</p><p>在除C语言之外的11种语言中，所有其他开源模型，包括PolyCoder，都明显比Codex更糟糕。这可能是因为PolyCoder是在不同语言的不平衡混合上训练的，C和C++密切相关，并且在整个训练语料库中占主导地位。因此，较大的总容量(因为长文件)使C语言成为PolyCoder最“青睐”的语言。PolyCoder在c++中表现不如Codex的原因可能是由于c++语言的复杂性和Codex的上下文窗口大小明显较长(4096，而PolyCoder的2048)，或者因为Codex可能在更多的c++训练数据上进行训练。</p><p>资源：<a href="https://github.com/2FVHellendoorn/2FCode-LMs">https://github.com/2FVHellendoorn/2FCode-LMs</a></p><h2 id="Synchromesh"><a href="#Synchromesh" class="headerlink" title="Synchromesh"></a>Synchromesh</h2><p>Synchromesh: 齿轮的同时咬合装置。</p><h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>大模型虽好，但它们在code generation任务中：</p><ul><li><p>可能错误地意会 developer 的 intent</p></li><li><p>生成跑不起来的代码</p></li><li><p>无法通过仅扩大模型规模来提升性能的可靠性</p></li></ul><h4 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h4><h5 id="framework"><a href="#framework" class="headerlink" title="framework"></a>framework</h5><p><img src="/2023/01/20/codeLMs/image-20230120125043513.png" alt="image-20230120125043513"></p><p>SYNCHROMESH框架概述。对于用户的查询，首先使用目标相似度调优(Target Similarity Tuning, TST)检索高相关性示例。然后，通过约束语义解码(Constrained Semantic Decoding, CSD)对程序进行增量采样，它查询补全引擎(Completion Engine, CE)以在代码生成期间强制执行约束，而无需重新训练或微调语言模型。</p><h5 id="TST"><a href="#TST" class="headerlink" title="TST"></a>TST</h5><p><img src="/2023/01/20/codeLMs/image-20230120125212608.png" alt="image-20230120125212608"></p><p>目标相似度调优改进了合成SOL查询的示例选择的例子。在(a)中，提示示例遗漏了关键查询结构(分组和计数)。对于这个例子，GPT-3生成了一个无效的查询(b)。对于TST，检索了一个相关的例子，GPT-3成功地适应了这个例子来回答用户的问题(c)。</p><p>（Sentence-Bert：语义相似度计算。</p><p>ab 流程失败原因：基于了描述相似性而不是 SQL 查询的相似性（简单描述：形式上相似，但逻辑上不相似）。比如在这里，所选示例中的SQL查询的结构过于简单，与所需 SQL 查询的结构有很大的不同。</p><p>加入 TST：</p><p>$D$ 是程序和相关表达的数据集，$D_i&#x3D;(p_i,u_i)$ 。$S(p_a,p_b)∈[0,1]$ 表示程序之间的归一化相似度度量。 如果 $f_\theta$ 是一个预训练好的自然语句相似度模型，那么 TST 就是对 $f$ 进行微调来根据 $S$ 给出的目标程序的描述来预测目标程序之间的相似度。最后，将均方误差损失最小化：</p><p><img src="/2023/01/20/codeLMs/image-20230120134330476.png" alt="image-20230120134330476"></p><p>论文中使用了 classical tree edit distance algorithm 来定义 $S$ 以比较抽象语法树（Abstract Syntax Trees）。</p><p>对应 ac 流程，可以发现问题和示例的表述在自然语言中完全不同，但它们在所描述的SQL查询中具有相似性。</p><h5 id="CSD-amp-CE"><a href="#CSD-amp-CE" class="headerlink" title="CSD &amp; CE"></a>CSD &amp; CE</h5><p>TST 只能引导 LLMs 走向正确的结构，无法保证正确地填充所有具体的实现细节。</p><p><img src="/2023/01/20/codeLMs/image-20230120161144651.png" alt="image-20230120161144651"></p><p>可以看到，a 中生成反了（一般来说，无约束语言模型经常犯这样的错误：使用未声明的变量、在生成复杂表达式时失去对嵌套级别的追踪或者使用错误类型的参数调用函数，而即使是最小的错误也会阻止生成的代码执行）。</p><p>CSD 通过构造(而不是事后修复)来防止实现错误。假设我们可以访问一个 oracle（我们称之为 CE），它可以接受一个部分程序并返回所有 tokens ，这些 tokens 可以将该部分程序扩展为一个完整的正确程序。当LLM逐个 tokens 生成程序时，CSD 确保从 CE 返回的集合中采样下一个 tokens 。如上图，在“on”子句中生成“T1.”之后，SQL CE解析名称并约束模型输出“Flights”表中的一列。这将修复先前在生成过程中看到的错误，并生成正确的SQL查询。</p><p>给定一个部分程序，CE 将返回一个正则表达式，该正则表达式与后面的有效 tokens 匹配。</p><p>CE 本质上是对 Decoder 的输出词表分布做了限制。CE 为人工实现。</p><p><img src="/2023/01/20/codeLMs/image-20230120171251115.png" alt="image-20230120171251115"></p><p>（DoB: Date of Birth.</p><h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><p><img src="/2023/01/20/codeLMs/image-20230120173223547.png" alt="image-20230120173223547"></p><p>Exec. 和 Acc. 都表示匹配精度。</p><h4 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h4><ul><li>在decoding阶段动态执行 constrain，表现比 generate-then-test 好。</li><li>显著提高了生成代码的合法性；有助于生成更长的代码。</li><li>使用 SYNCHROMESH 方法增强的LLMs表现不如监督模型，但比 CodeX 好。</li></ul><h2 id="Jigsaw"><a href="#Jigsaw" class="headerlink" title="Jigsaw"></a>Jigsaw</h2><p>Jigsaw是多模态的（如下图所示），它可以通过输入表示意图的自然语言字符串或一组输入-输出示例来生成作为输出的代码片段。</p><p><img src="/2023/01/20/codeLMs/image-20230120181342814.png" alt="image-20230120181342814"></p><h4 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h4><ul><li>提出了一种架构，通过使用基于程序分析和合成的技术和多模态规范来增强黑盒ptlm来执行代码合成。已经在一个叫做Jigsaw的工具中实现了架构。已经开发了一个Jupyter笔记本扩展，允许用户与系统无缝交互。</li><li>描述了ptlm所犯的常见错误类别，即引用错误、参数错误和语义错误。基于这些错误，在Jigsaw中设计了程序分析和合成技术，以修复由ptlm生成的代码片段中的此类错误。还设计了从用户反馈中学习的技术，并随着使用而改进。</li><li>已经创建了两个具有多模态规范的Pandas数据集(在补充材料中提供，并将发布给社区使用)。通过使用两个最先进的PTLMs，发现与两个数据集上的基线相比Jigsaw的精度显著提高。</li></ul><h4 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h4><p><img src="/2023/01/20/codeLMs/image-20230120185847376.png" alt="image-20230120185847376"></p><p>核心：post-processing 阶段。包括特征、转换错误的代码片段、从用户反馈中改进。</p><h5 id="Pre-trained-Language-Models"><a href="#Pre-trained-Language-Models" class="headerlink" title="Pre-trained Language Models"></a>Pre-trained Language Models</h5><p><img src="/2023/01/20/codeLMs/image-20230120191933484.png" alt="image-20230120191933484"></p><h5 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h5><p><img src="/2023/01/20/codeLMs/image-20230120192150106.png" alt="image-20230120192150106"></p><p>维护一个包含可能的问答对的上下文库（Jigsaw通过从Pandas的API文档中抓取和注释示例，以及用于教授API的其他示例资源(来自教程等)，离线创建了一个上下文银行。），然后从上下文库中选择与当前查询相似的元素，并将这些元素添加到上下文中。当用户提出一个问题时，该问题将被馈送到上下文选择器，上下文选择器使用文本相似度度量从上下文库中挑选最相关的提示。</p><p>在Jigsaw无法产生正确答案的情况下，让用户对不正确的Jigsaw代码进行更改，并使用这样的反馈来增强上下文银行。</p><p>ptlm还接受一个称为温度的输入参数。温度越低，准确的答案就越少。数值越高，得到的答案就越不准确，但也就越多样。</p><h5 id="Post-processing"><a href="#Post-processing" class="headerlink" title="Post-processing"></a>Post-processing</h5><p>Jigsaw 的后处理步骤的目标是过滤和转换 PTLM 产生的输出，以产生正确的答案。</p><p>衡量正确性的标准是生成的代码应该通过用户指定的 I&#x2F;O 示例。</p><p>大约30%-60%的情况(取决于 PTLM 和数据集)，PTLM 产生正确的输出。在其余的情况下，Jigsaw 使用PTLM生成的候选解决方案作为起点，并使用简单的程序分析和综合技术对候选代码片段执行转换，以生成正确的解决方案。</p><h6 id="Correctness-checks"><a href="#Correctness-checks" class="headerlink" title="Correctness checks"></a>Correctness checks</h6><p>在有I&#x2F;O示例的情况下，我们从每个指定的示例输入开始运行候选代码段，并检查所产生的输出是否与相应的指定输出一致。</p><h6 id="Variable-Name-transformations"><a href="#Variable-Name-transformations" class="headerlink" title="Variable Name transformations"></a>Variable Name transformations</h6><p>在某些情况下，PTLM 生成了准确的代码片段，但是使用了不正确的变量名。由于用户在自然语言描述或测试用例中指定输入和输出变量，这个后处理步骤使用来自多模态输入的这些信息，以及范围内的变量名，通过系统地搜索潜在变量，并尝试变量名的可能排列和组合，以通过测试用例。</p><p><img src="/2023/01/20/codeLMs/image-20230120193527123.png" alt="image-20230120193527123"></p><h6 id="Argument-transformations"><a href="#Argument-transformations" class="headerlink" title="Argument transformations"></a>Argument transformations</h6><p>在某些情况下，PTLM 生成的代码片段带有正确的方法名称和方法序列，但是带有不正确的参数。</p><blockquote><p>replace ‘United States’ in ‘location’ by ‘US’ and ‘3434’ in ‘zip’ by ‘4343’</p></blockquote><p><img src="/2023/01/20/codeLMs/image-20230120193816788.png" alt="image-20230120193816788"></p><p>应该为：</p><p><img src="/2023/01/20/codeLMs/image-20230120193852399.png" alt="image-20230120193852399"></p><p>“在这种情况下，这个后处理步骤系统地从推断的参数空间中搜索给定方法&#x2F;函数名序列的参数。为了在参数空间上实现系统搜索，我们采用Autopandas工具[9]所使用的方法，并进行了以下修改。Autopandas使用图形神经网络，将I&#x2F;O示例作为输入，来选择方法名。然而，我们需要大量特定领域的数据来训练这样的神经网络。在我们的例子中，我们简单地从PTLM的输出中提取方法名，给定自然语言查询(这很容易扩展到Pandas以外的编程领域)。执行搜索的参数空间是通过使用自然语言文本输入、PTLM输出中的参数、数据帧模式中的列名以及作用域中的变量推断出来的。我们扩展了Autopandas中的生成器，以考虑复杂的数据类型，如列表和字典，并且我们扩展了考虑的api集，除了返回Pandas数据框架类型的api外，还包括返回Pandas系列类型(能够保存任何类型数据的一维标记数组)的api。通过这些修改，我们发现Jigsaw能够将PTLM生成的一些错误代码片段转换为正确的代码片段(如第5节所示)。”</p><h6 id="AST-to-AST-transformations"><a href="#AST-to-AST-transformations" class="headerlink" title="AST-to-AST transformations"></a>AST-to-AST transformations</h6><p>有时候会反复犯一些小错误，可以通过适当的AST-to-AST转换进行修复，这是从用户与Jigsaw的交互中学习到的。</p><p>作为一个具体的例子，我们发现GPT-3经常忽略按位的not操作符，并产生如下代码:</p><p><img src="/2023/01/20/codeLMs/image-20230120194205393.png" alt="image-20230120194205393"></p><p>而不是：</p><p><img src="/2023/01/20/codeLMs/image-20230120194238293.png" alt="image-20230120194238293"></p><p>（文章中的小错误：</p><p><img src="/2023/01/20/codeLMs/image-20230120194426517.png" alt="image-20230120194426517"></p><p><img src="/2023/01/20/codeLMs/image-20230120194514894.png" alt="image-20230120194514894"></p><p>而不是：</p><p><img src="/2023/01/20/codeLMs/image-20230120194523923.png" alt="image-20230120194523923"></p><h5 id="Learning-from-user-feedback"><a href="#Learning-from-user-feedback" class="headerlink" title="Learning from user feedback"></a>Learning from user feedback</h5><p>Jigsaw的用户界面(集成到 Jupyter notebook 中)旨在让用户在 Jigsaw 错误的情况下提交正确的代码。Jigsaw可以通过吸收用户反馈进行改进。具体来说，当更多用户与Jigsaw交互时，作者设计了用于在预处理模块中更新上下文银行和在后处理步骤中进行AST-to-AST转换的技术。</p><h2 id="Data2Vis"><a href="#Data2Vis" class="headerlink" title="Data2Vis"></a>Data2Vis</h2><h4 id="主要工作"><a href="#主要工作" class="headerlink" title="主要工作"></a>主要工作</h4><ol><li>将可视化设计表述为序列翻译问题的序列；</li><li>在小规模的训练集上训练模型，然后有效生成测试数据的可视化，展示其可行性；</li><li>开源的基于web的应用程序Data2Vis.</li></ol><p>本文是第一个将深层神经翻译运用到可视化生成中的研究，之后的研究可以考虑从大规模数据中隐式的学习可视化设计和可视化分析规则。</p><h4 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h4><p><img src="/2023/01/20/codeLMs/image-20230120195131749.png" alt="image-20230120195131749"></p><p>将数据可视化问题表述为一个序列到序列的翻译问题（seq2seq），我们输入序列是数据集（json格式），输出序列是一个有效的Vega-lite可视化格式。</p><p>为了能将seq2seq模型运用到非序列问题中，研究考虑使用双向RNN和注意力机制。</p><p>模型的基础是一个添加注意力机制的编码器-解码器架构。编码器是一个双向RNN。解码器就是基于编码器的输出结果去计算目标序列的概率的RNN。这个概率和解码器RNN的结果，目标序列之前的结果，以及注意力向量（context vector）有关。</p>]]></content>
    
    
    <categories>
      
      <category>IDEAS Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型学习笔记</tag>
      
      <tag>NL-PL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于快节奏化的一些思考</title>
    <link href="/2023/01/17/230117/"/>
    <url>/2023/01/17/230117/</url>
    
    <content type="html"><![CDATA[<p>现在的生活愈来愈快节奏化与碎片化，我也受其影响颇多——今天上午我打算看一下新出的三体电视剧，但按理说会看得津津有味的剧，看到一半竟然就看不下去了。想来是因为电视剧拍的节奏稍慢（这样的节奏用于表现三体正合适，没有说这样的节奏不好的意思），而我已经被快节奏的视频格式化了头脑，变得只能接受密集程度高的信息，愈来愈看不了这种慢节奏的视频了。</p><p>回想起来，这种情况持续很久了。有时候想看个电影，一想，唉，找资源再看好麻烦啊，而且还要用掉两个小时的时间，于是直接在b站一搜，十分钟看完了这个电影的解说，把情节大体过了一遍就结束了。但实际上，资源很容易就能找到，这两个小时的时间也很容易抽出来，我缺少的只是坐下来看两个小时电影的耐心罢了。</p><p>其实在某些时候，快节奏化确实是有利的，比如有时候急需了解一个名词或一个模型又不需要深究时，在 google、知乎、csdn 上搜索看下简介肯定是比查阅其出处论文然后再读一遍论文要更方便的，再比如看网课时，在能理解老师讲述内容上的倍速播放能加快学习效率。但这样一来，我们头脑中对信息密集程度的阈值愈来愈高，渐渐地，对信息密集程度低的事物的接受程度也相应的愈来愈低了，在一些不该快节奏的事情上，也不由自主地将其快节奏化。</p><p>看到一句话放在这里很合适：我们的生活可以快节奏，但不能习惯快节奏。</p><p>我想，可以采用快慢节奏相结合的方式来调和吧，在该快节奏的地方快节奏，同时避免接受一些意义不大的碎片化信息，然后多做一些如读书、看完整的电影等慢节奏的事情。具体来说呢，少看b站，少看知乎，多读书，在需要用到b站、知乎等软件时，明确自己的目的再搜索，而不是看着看着就看到了推荐内容上去，在休息时也尽量少去看b站，改为运动一下或者读感兴趣的书这一类的节奏较慢（这里用非快节奏可能更合适，因为运动好像也不能说是慢节奏）的活动。</p><p>希望能奏效 : )</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Language Models 补充</title>
    <link href="/2023/01/13/LanguageModels2/"/>
    <url>/2023/01/13/LanguageModels2/</url>
    
    <content type="html"><![CDATA[<h2 id="BERT-vs-GPT"><a href="#BERT-vs-GPT" class="headerlink" title="BERT vs GPT"></a>BERT vs GPT</h2><h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/2023/01/13/LanguageModels2/image-20230113194643214.png" alt="Encoder→BERT,Decoder→GPT"></p><ul><li>Masked Multi-Head-Attention。使用mask的原因是因为在预测句子的时候，当前时刻是无法获取到未来时刻的信息的。也就是Multi-Head-Attention可以看到Input的整个句子，而Masked Multi-Head-Attention只能看到当前输入之前的内容，无法看到之后的内容。</li><li>预训练任务。BERT：填空；GPT：预测接下来会出现的token是什么。</li><li>fine-tuning。这就好比一个人博览群书，你问他什么类型的问题，他都可以顺手拈来。</li></ul><h2 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h2><p>Text-to-Text Transfer Transformer</p><p>文本到文本传输转换器</p><h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p><img src="/2023/01/13/LanguageModels2/image-20230113163442494.png" alt="T5"></p><p>将翻译、分类、回归、摘要生成等任务都统一转成Text-to-Text任务，从而使得这些任务在训练(pre-train和fine-tune)时能够使用相同的目标函数，在测试时也能使用相同的解码过程。</p><p>在形式上统一了自然语言理解和自然语言生成任务的外在表现形式。</p><p>在下游任务上fine-tune模型时，为了告诉模型当前要做何种任务，我们会给每条输入样本加一个与具体任务相关的前缀。</p><ul><li>翻译前缀 translate English to German:</li><li>分类前缀 cola sentence:</li><li>摘要前缀 summarize:</li></ul><p>T5 的baseline模型直接采用标准的Transformer encoder-decoder结构，以便在生成任务和分类任务上都能取得不错的效果。</p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>无监督 &amp; 有监督。</p><p>denoising objective：</p><p><img src="/2023/01/13/LanguageModels2/image-20230113164643567.png" alt="很像MLM"></p><h4 id="新的尝试"><a href="#新的尝试" class="headerlink" title="新的尝试"></a>新的尝试</h4><h5 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h5><ul><li>fully-visible attention mask：输出序列的每个元素可以看见输入序列的每个元素。</li><li>causal attention mask：输出序列的每个元素只能看对应位置及之前的输入序列的元素，无法看见未来的元素。</li><li>causal with prefix attention mask：输入序列的一部分前缀采用fully-visible attention mask，其余部分采用 causal attention mask。</li></ul><p><img src="/2023/01/13/LanguageModels2/image-20230113170256170.png" alt="新的模型架构"></p><p>在最左侧的Encoder-Decoder结构中，Encoder部分采用fully-visible attention mask，而Decoder部分采用causal attention mask。</p><p>中间的Language model结构中，采用causal attention mask。</p><p>最右侧的Prefix LM结构中，采用causal with prefix attention mask。比如在翻译任务中，给定训练样本translate English to German: That is good. target: Das ist gut.，我们对translate English to German: That is good. target:采用fully-visible attention mask，对Das ist gut.采用causal attention mask。</p><p>结果：</p><p><img src="/2023/01/13/LanguageModels2/image-20230113193754376.png" alt="结果"></p><h5 id="随机Mask的比例"><a href="#随机Mask的比例" class="headerlink" title="随机Mask的比例"></a>随机Mask的比例</h5><p>15% or ？</p><h5 id="总表"><a href="#总表" class="headerlink" title="总表"></a>总表</h5><p><img src="/2023/01/13/LanguageModels2/image-20230113121615609.png" alt="做了很全面的工作"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>预训练策略：采用multi-task预训练方式(即无监督任务和有监督任务一起预训练)，在对比迁移方法一小节中我们发现Multi-task pretraining + fine-tuning的效果和Unsupervised pre-training + fine-tuning的效果差不多，但是前者在预训练过程还能够监控下游任务的性能，因此作者最后采用Multi-task pre-training。</p><p>作者也说了，本文的目的不是提出一个新的方法，而是对NLP领域的一些技术支撑点提供一个较为全面的分析视角。</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p><a href="https://github.com/google-research/text-to-text-transfer-transformer">https://github.com/google-research/text-to-text-transfer-transformer</a></p><h2 id="mT5"><a href="#mT5" class="headerlink" title="mT5"></a>mT5</h2><p>mT5 → Multilingual T5 → 支持中文</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><p><a href="https://github.com/google-research/multilingual-t5">https://github.com/google-research/multilingual-t5</a></p><h2 id="chatGPT"><a href="#chatGPT" class="headerlink" title="chatGPT"></a>chatGPT</h2><p><img src="/2023/01/13/LanguageModels2/image-20230113203948996.png" alt="提到说使用了RLHF方法"></p><h4 id="RLHF"><a href="#RLHF" class="headerlink" title="RLHF"></a>RLHF</h4><p>Reinforcement Learning from Human Feedback</p><p>基于人类反馈的强化学习。</p><p>RLHF的训练过程可以分解为三个核心步骤：</p><ul><li>预训练语言模型（LM）</li><li>收集数据并训练奖励模型</li><li>通过强化学习微调 LM</li></ul><p>一个问题是训练这样的模型需要多少数据和人力标注？Hug给出的回答是，因为人工写回答要求质量高所以不能用众包。不过对RM模型的训练，需要的标注不多。</p><p><img src="/2023/01/13/LanguageModels2/image-20230113202215940.png" alt="三大核心步骤"></p><p><img src="/2023/01/13/LanguageModels2/image-20230113202337463.png" alt="预训练语言模型"></p><p><img src="/2023/01/13/LanguageModels2/image-20230113202347695.png" alt="收集结果→打分（排名）→训练奖励模型"></p><ol><li>为什么不人工直接打分？因为打分是主观的需要归一化，而排序一般大家会有共同的结论：对同一个问题，A和B哪个回答更好。</li><li>有了一组一组的偏序（A&gt;B, A&gt;C, C&gt;B）怎么得到每个回答的奖励分数？使用了Elo排名系统，来转换得到分数。</li></ol><p><img src="/2023/01/13/LanguageModels2/image-20230113202621869.png" alt="使用奖励模型微调语言模型"></p>]]></content>
    
    
    <categories>
      
      <category>IDEAS Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>大模型学习笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Language Models</title>
    <link href="/2023/01/10/LanguageModels/"/>
    <url>/2023/01/10/LanguageModels/</url>
    
    <content type="html"><![CDATA[<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h4 id="Epoch"><a href="#Epoch" class="headerlink" title="Epoch"></a>Epoch</h4><p>当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一次epoch。（也就是说，所有训练样本在神经网络中都进行了一次正向传播和一次反向传播 ）</p><p>再通俗一点，一个Epoch就是将所有训练样本训练一次的过程。</p><p>然而，当一个Epoch的样本（也就是所有的训练样本）数量可能太过庞大（对于计算机而言），就需要把它分成多个小块，也就是就是分成多个Batch 来进行训练。</p><h4 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h4><p>批 &#x2F; 一批样本。</p><h4 id="Batch-Size"><a href="#Batch-Size" class="headerlink" title="Batch_Size"></a>Batch_Size</h4><p>每批样本的大小。</p><h4 id="Iteration"><a href="#Iteration" class="headerlink" title="Iteration"></a>Iteration</h4><p>一次迭代。训练一个Batch就是一次Iteration（这个概念跟程序语言中的迭代器相似）</p><h4 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h4><p>PPL是用在自然语言处理领域（NLP）中，衡量语言模型好坏的指标。它主要是根据每个词来估计一句话出现的概率，并用句子长度作normalize。PPL越小，一句我们期望的sentence出现的概率就越高。</p><h4 id="Zero-shot-learning"><a href="#Zero-shot-learning" class="headerlink" title="Zero-shot learning"></a>Zero-shot learning</h4><p>Zero-shot learning：零样本学习。</p><p>利用高维语义特征代替样本的低维特征，使得训练出来的模型具有迁移性。</p><p>舍去低维特征，不需要“面面俱到”，达到分类目的。</p><h4 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h4><p>主要应用：图片处理。</p><p>背景：</p><ol><li>图像需要处理的数据量太大，导致成本很高，效率很低</li><li>图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高</li></ol><p>结构：</p><ul><li><p>卷积层：使用卷积核来过滤图像的各个小区域。</p><p><img src="/2023/01/10/LanguageModels/image-20230110183519954.png" alt="Convolved Feature"></p><p>在具体应用中，往往有多个卷积核，可以认为，每个卷积核代表了一种图像模式，如果某个图像块与此卷积核卷积出的值大，则认为此图像块十分接近于此卷积核。如果我们设计了6个卷积核，可以理解：我们认为这个图像上有6种底层纹理模式，也就是我们用6中基础模式就能描绘出一副图像。</p><p>总结：通过卷积核的过滤提取出图片中局部的特征。</p></li><li><p>池化层：数据降维，避免过拟合。</p><p><img src="/2023/01/10/LanguageModels/image-20230110183642038.png" alt="Pooled Feature"></p></li><li><p>全连接层：输出结果。</p><p>在全连接层之前可以有多个卷积层和池化层。</p><p><img src="/2023/01/10/LanguageModels/image-20230108171350085.png" alt="Full Connection"></p></li></ul><h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><p>CNN 和普通的算法大部分都是输入和输出的一一对应，也就是一个输入得到一个输出。不同的输入之间是没有联系的。</p><p>RNN 跟传统神经网络最大的区别在于每次都会将前一次的输出结果，带到下一次的隐藏层中，一起训练。</p><p><img src="/2023/01/10/LanguageModels/image-20230110183721847.png" alt="RNN"></p><p>问题：短期记忆影响较大，无法处理很长的输入序列；由于依赖前步输出，无法进行并行计算。</p><h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p>LSTM 可以保留较长序列数据中的“重要信息”，忽略不重要的信息。这样就解决了 RNN 短期记忆的问题。</p><h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>Gated Recurrent Unit – GRU 是 LSTM 的一个变体，他主要是在 LSTM 的模型上做了一些简化和调整，在训练数据集比较大的情况下可以节省很多时间。</p><h4 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h4><p>Softmax 是一种激活函数，它可以将一个数值向量归一化为一个概率分布向量，且各个概率之和为1。Softmax 可以用来作为神经网络的最后一层，用于多分类问题的输出。</p><h2 id="Encoder-Decoder-amp-Seq2Seq"><a href="#Encoder-Decoder-amp-Seq2Seq" class="headerlink" title="Encoder-Decoder &amp; Seq2Seq"></a>Encoder-Decoder &amp; Seq2Seq</h2><h4 id="Encoder-Decoder-模型"><a href="#Encoder-Decoder-模型" class="headerlink" title="Encoder-Decoder 模型"></a>Encoder-Decoder 模型</h4><p>不是某种具体的算法，而是一类算法的统称。</p><p>机器学习的核心思路：将现实问题转化为数学问题，通过求解数学问题，从而解决现实问题。</p><p><img src="/2023/01/10/LanguageModels/image-20230108110644217.png" alt="Encoder"></p><p><img src="/2023/01/10/LanguageModels/image-20230108110653654.png" alt="Decoder"></p><p><img src="/2023/01/10/LanguageModels/image-20230108110713934.png" alt="Encoder-Decoder"></p><p>需要说明的点：</p><ol><li>无论输入输出长度如何，中间的向量C长度固定（这也是缺陷）。</li><li>根据不同的问题选择不同的 Encoder 和 Decoder，可以是一个 RNN，但通常是其变种 LSTM 或者 GRU。</li></ol><p>应用：</p><ul><li>text - text</li><li>audio - text</li><li>image&#x2F;video - text</li></ul><h4 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h4><p>字面意思，输入一个序列，输出一个序列。</p><p>特点：输入序列和输出序列的长度可变。</p><p><em>在 Seq2Seq 框架提出之前，深度神经网络在图像分类等问题上取得了非常好的效果。在其擅长解决的问题中，输入和输出通常都可以表示为固定长度的向量，如果长度稍有变化，会使用补零等操作。然而许多重要的问题，例如机器翻译、语音识别、自动对话等，表示成序列后，其长度事先并不知道。因此如何突破先前深度神经网络的局限，使其可以适应这些场景，成为了13年以来的研究热点，Seq2Seq 框架应运而生。</em></p><p>属于 Encoder-Decoder 的大范畴。</p><p>缺点：非常占内存；大数据量上不容易调参。</p><h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><h5 id="Encoder-Decoder-模型的缺陷："><a href="#Encoder-Decoder-模型的缺陷：" class="headerlink" title="Encoder-Decoder 模型的缺陷："></a>Encoder-Decoder 模型的缺陷：</h5><p>Encoder 和 Decoder 之间只有一个向量 C 来传递信息，且 C 的长度固定 → 输入信息过长时，会丢失掉一部分信息。</p><p>Attention 机制就是为了解决”信息过长，信息丢失”的问题。</p><h5 id="引入了-Attention-机制的-Encoder-Decoder-模型"><a href="#引入了-Attention-机制的-Encoder-Decoder-模型" class="headerlink" title="引入了 Attention 机制的 Encoder-Decoder 模型"></a>引入了 Attention 机制的 Encoder-Decoder 模型</h5><p>Encoder 不再将整个输入序列编码为固定长度的中间向量 C，而是编码为一个向量的序列。</p><p><img src="/2023/01/10/LanguageModels/image-20230108121728990.png" alt="Encoder-Decoder with attention"></p><p>在产生每一个输出的时候，都能够做到充分利用输入序列所携带的信息。</p><p>那么，什么是 Attention 机制？</p><h2 id="Attention-机制"><a href="#Attention-机制" class="headerlink" title="Attention 机制"></a>Attention 机制</h2><h4 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h4><p>关注全部 → 关注重点。</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><h5 id="参数少"><a href="#参数少" class="headerlink" title="参数少"></a>参数少</h5><p>模型复杂度相对 CNN、RNN 等更小，参数也更少，对算力要求较低。</p><h5 id="速度快"><a href="#速度快" class="headerlink" title="速度快"></a>速度快</h5><p>解决了 RNN 不能并行计算的问题，Attention 机制的每一步计算都不依赖上一步的计算结果，因此可以和 CNN 一样并行处理。</p><h5 id="效果好"><a href="#效果好" class="headerlink" title="效果好"></a>效果好</h5><p>Attention 机制引入之前：就像是遥远的记忆会变得模糊一样，长距离的信息会被弱化。</p><p>Attention 机制引入之后：挑重点进行处理，文本较长不妨碍抓住重点。</p><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>简单理解：encoder 层的输出经过加权平均后再输入到 decoder 层中。</p><p><img src="/2023/01/10/LanguageModels/image-20230108124359908.png" alt="Attention"></p><ol><li>对 query 和 key 进行相似度计算，得到权值；</li><li>将权值进行归一化，得到直接可用的权重；</li><li>将权重和 value 进行加权求和。</li></ol><h4 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h4><p><img src="/2023/01/10/LanguageModels/image-20230108124824075.png" alt="Attention种类"></p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><h4 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h4><p>左边被”N×“的为 Encoder，右边被“N×”的为 Decoder。</p><p><img src="/2023/01/10/LanguageModels/image-20230108182646123.png" alt="Transformer"></p><h4 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h4><p>表达元素内部之间的 attention 关系，输入之间的 QKV 会互相影响。</p><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><p>”多头“：对同一key、value、query抽取不同信息，相当于平行复制后随机初始化参数，从而使每个 self-attention 模块具有不同的假设空间。</p><p>使用多个独立的 Attention 池化，合并每个 head 的输出得到最终输出。</p><p>目的：这种结构设计能让每个注意力机制通过 QKV 映射到不同的空间去学习特征，去优化每个词汇的不同特征部分，从而均衡同一种注意力机制可能产生的偏差，让词义拥有来自更多元的表达，实验表明可以从而提升模型效果。</p><p><img src="/2023/01/10/LanguageModels/image-20230108174515578.png" alt="Multi-Head Attention"></p><h4 id="Masked-Multi-Head-Attention"><a href="#Masked-Multi-Head-Attention" class="headerlink" title="Masked Multi-Head Attention"></a>Masked Multi-Head Attention</h4><p>Decoder 对序列中某个元素进行输出时，不应该考虑该元素之后的元素。</p><p>↓ 通过掩码实现</p><p>计算 $x_i$ 输出时，假装当前序列长度为 $i$。</p><h4 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h4><p>除了注意力子层，编码器和解码器中的每一层都包含一个全连接的前馈网络，该网络分别且相同地应用于每个位置。这包括两个线性转换，中间有一个 ReLu 激活。</p><p><img src="/2023/01/10/LanguageModels/image-20230108183006265.png" alt="Feed-Forward"></p><p>作用：将输入形状由 (b, n, d) 变换为 (bn, d)、输出形状由 (bn, d) 变换为 (b, n, d)。避免了n 的变化导致的输入维度不稳定。</p><p>b: batchsize，多少个句子；</p><p>n: 序列长度，句子中有多少个字；</p><p>d: dimension，字是多少维。</p><h4 id="Add-amp-Norm"><a href="#Add-amp-Norm" class="headerlink" title="Add &amp; Norm"></a>Add &amp; Norm</h4><p>Add：</p><p>将 Multi-Head Attention 的输入与输出加起来。</p><p>Norm： </p><p>Layer Normalization。</p><p>不能用 Batch Normalization：</p><p>BN 是每个通道样本间归一化，LN 是每个样本通道间归一化。</p><p>有 b 句话，每句话有 len 个词，每个词由 d 个特征表示，BN 是对所有句子所有词的某一特征做归一化，LN 是对某一句话的所有词所有特征做归一化。</p><p>不同句子字数不同，无法进行句间归一化。</p><h4 id="信息传递"><a href="#信息传递" class="headerlink" title="信息传递"></a>信息传递</h4><p>将 Encoder 的输出 y1 ~ yn 分别给到 Decoder 中的每个块。</p><h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><p>Transformer 中的输入由 Word Embedding 和 Positional Embedding 相加得到。</p><h5 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h5><p>使用 Word2Vec、Glove等算法预训练得到，也可以在 Transformer 中训练得到。</p><h5 id="Positional-Embedding"><a href="#Positional-Embedding" class="headerlink" title="Positional Embedding"></a>Positional Embedding</h5><p>表示单词出现在句子中的位置。</p><p><img src="/2023/01/10/LanguageModels/image-20230108200234061.png" alt="Positional Embedding"></p><p>pos 表示单词在句中的位置，d 表示 PE 的维度（与 Word Embedding 一致），2i 表示偶数维度，2i+1 表示奇数维度。</p><p>为什么这样表示？</p><ol><li>使 PE 能够适应比训练集里面所有句子更长的句子，假设训练集里面最长的句子是有 20 个单词，突然来了一个长度为 21 的句子，则使用公式计算的方法可以计算出第 21 位的 Embedding。</li><li>可以让模型容易地计算出相对位置，对于固定长度的间距 k，PE(pos+k) 可以用 PE(pos) 计算得到。因为 Sin(A+B) &#x3D; Sin(A)Cos(B) + Cos(A)Sin(B), Cos(A+B) &#x3D; Cos(A)Cos(B) - Sin(A)Sin(B)。</li></ol><h2 id="Pre-train-Model"><a href="#Pre-train-Model" class="headerlink" title="Pre-train Model"></a>Pre-train Model</h2><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>标注资源稀缺而无标注资源丰富：某种特殊的任务只存在非常少量的相关训练数据，以至于模型不能从中学习总结到有用的规律。</p><h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><ol><li>模型角度：模型参数不再是随机初始化，而是通过某些特定任务（如语言模型）进行预训练；</li><li>数据角度：将训练任务拆解成共性学习和特性学习两个步骤。</li></ol><h4 id="学习任务的分解"><a href="#学习任务的分解" class="headerlink" title="学习任务的分解"></a>学习任务的分解</h4><p>“预训练“的做法一般是将大量低成本收集的训练数据放在一起，经过某种预训方法去学习其中的共性，然后将其中的共性“移植”到特定任务的模型中，再使用相关特定领域的少量标注数据进行“微调”，这样的话，模型只需要从”共性“出发，去“学习”该特定任务的“特殊”部分即可。</p><p>举例理解：会说汉语→法律文献专业名词提取 vs 不会说汉语→法律文献专业名词提取。</p><p>先学习汉语，再进行法律文献专业名词提取→学习任务分解。</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>自编码预训练（AE）：BERT，对应了 encoder 的预训练，更适合文本理解任务；</p><p>自回归预训练（AR）：GPT，对应了 decoder 的预训练，更适合文本生成任务。</p><h2 id="BERT-amp-RoBERTa"><a href="#BERT-amp-RoBERTa" class="headerlink" title="BERT &amp; RoBERTa"></a>BERT &amp; RoBERTa</h2><h4 id="BERT-Bidirectional-Encoder-Representation-from-Transformers"><a href="#BERT-Bidirectional-Encoder-Representation-from-Transformers" class="headerlink" title="BERT (Bidirectional Encoder Representation from Transformers)"></a>BERT (Bidirectional Encoder Representation from Transformers)</h4><h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><p>BERT 不再像以往一样采用传统的单向语言模型或者把两个单向语言模型进行浅层拼接的方法进行预训练，而是采用新的 masked language model（MLM），以致能生成深度的双向语言表征。</p><h5 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h5><ol><li>采用 MLM 对双向的 Transformer 进行预训练，以生成能融合左右上下文信息的深层双向语言表征。</li><li>预训练后，只需要添加一个额外的输出层进行微调，就可以在各种各样的下游任务中取得 state-of-the-art 的表现。在这过程中并不需要对 BERT 进行任务特定的结构修改。</li></ol><h5 id="预训练过程"><a href="#预训练过程" class="headerlink" title="预训练过程"></a>预训练过程</h5><h6 id="MLM"><a href="#MLM" class="headerlink" title="MLM"></a>MLM</h6><p>MLM可以理解为完形填空，作者会随机mask每一个句子中15%的词，用其上下文来做预测，例如：my dog is hairy → my dog is [MASK]。</p><p>此处将hairy进行了mask处理，然后采用非监督学习的方法预测mask位置的词是什么，但是该方法有一个问题，因为是 mask 15%的词，其数量已经很高了，这样就会导致某些词在fine-tuning阶段从未见过，为了解决这个问题，作者做了如下的处理：</p><ul><li>80%的时间是采用[mask]，my dog is hairy → my dog is [MASK]；</li><li>10%的时间是随机取一个词来代替mask的词，my dog is hairy -&gt; my dog is apple；</li><li>10%的时间保持不变，my dog is hairy -&gt; my dog is hairy；</li></ul><p>使用随机词的原因：防止Transformer直接将[MASK]记为”hairy”，同时迫使模型更多地依赖于上下文信息来预测词汇。</p><h6 id="Next-Sentence-Prediction"><a href="#Next-Sentence-Prediction" class="headerlink" title="Next Sentence Prediction"></a>Next Sentence Prediction</h6><p>对 Sentence A 与其之后的 Sentence B 进行训练，其中 B 中50%的数据为 A 的下一条句子，剩余50%的数据为语料库中的随机句子。</p><p>使预训练的模型可以处理需要理解两个句子之间的关系的任务。</p><h5 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h5><p>BERT只使用了Transformer的Encoder模块，原论文中，作者分别用12层和24层Transformer Encoder组装了两套BERT模型，分别是：</p><p><img src="/2023/01/10/LanguageModels/image-20230109201517021.png" alt="BERT"></p><p>其中层的数量（即 Transformer Encoder 块的数量）为 L，隐藏层的维度为 H，自注意头的个数为 A。在所有例子中，我们将前馈&#x2F;过滤器（ Transformer Encoder 端的 feed-forward 层）的维度设置为 4H，即当 H&#x3D;768 时是 3072；当 H&#x3D;1024 是 4096。</p><p><img src="/2023/01/10/LanguageModels/image-20230109201814452.png" alt="BERT模型"></p><h5 id="输入-1"><a href="#输入-1" class="headerlink" title="输入"></a>输入</h5><p>BERT的输入词向量是三个向量之和：</p><ul><li>Token Embedding：词向量。</li><li>Segment Embedding：表明这个词属于哪个句子（NSP 需要两个句子）。</li><li>Position Embedding：学习出来的 embedding 向量。这与 Transformer 不同，Transformer 中是预先设定好的值。</li></ul><p><img src="/2023/01/10/LanguageModels/image-20230109204017869.png" alt="Input of BERT"></p><h5 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h5><p>BERT预训练模型的输出结果，无非就是一个或多个向量。下游任务可以通过精调（改变预训练模型参数）或者特征抽取（不改变预训练模型参数，只是把预训练模型的输出作为特征输入到下游任务）两种方式进行使用。</p><h5 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h5><ul><li>引入了Masked LM，使用双向 LM 做模型预训练；</li><li>为预训练引入了新目标 NSP，它可以学习句子与句子间的关系；</li><li>进一步验证了更大的模型效果更好： 12 –&gt; 24 层；</li><li>为下游任务引入了很通用的求解框架，不再为任务做模型定制；</li><li>刷新了多项 NLP 任务的记录，引爆了NLP无监督预训练技术。</li></ul><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul><li><p>[MASK]标记在实际预测中不会出现，训练时用过多[MASK]影响模型表现；</p></li><li><p>每个batch只有15%的token被预测，所以BERT收敛得比 left-to-right 模型要慢（它们会预测每个token）；</p></li><li><p>BERT对硬件资源的消耗巨大，大模型需要16个 tpu，历时四天；更大的模型需要64个 tpu，历时四天。</p></li></ul><h5 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h5><ul><li>句子或者段落的匹配类任务：Bert在预训练阶段增加了 NSP 任务，所以能够在预训练阶段学会一些句间关系的知识，而如果下游任务正好涉及到句间关系判断，就特别吻合 Bert 本身的长处。</li><li>适合解决输入长度不太长的NLP任务：而输入比较长的任务，典型的比如文档级别的任务，Bert解决起来可能就不太好。主要原因在于：Transformer的self attention机制因为要对任意两个单词做attention计算，所以时间复杂度是n平方，n是输入的长度。如果输入长度比较长，Transformer的训练和推理速度掉得比较厉害，于是，这点约束了Bert的输入长度不能太长。所以对于输入长一些的文档级别的任务，Bert就不容易解决好。结论是：Bert更适合解决句子级别或者段落级别的NLP任务。</li></ul><h4 id="RoBERTa（-A-Robustly-Optimized-BERT-Pretraining-Approach）"><a href="#RoBERTa（-A-Robustly-Optimized-BERT-Pretraining-Approach）" class="headerlink" title="RoBERTa（ A Robustly Optimized BERT Pretraining Approach）"></a>RoBERTa（ A Robustly Optimized BERT Pretraining Approach）</h4><p>从模型上来说，RoBERTa基本没有什么太大创新，主要是改变了预训练的方法。</p><h5 id="静态-Masking-vs-动态-Masking"><a href="#静态-Masking-vs-动态-Masking" class="headerlink" title="静态 Masking vs 动态 Masking"></a>静态 Masking vs 动态 Masking</h5><p>Bert对每一个序列随机选择15%的Tokens替换成[MASK]，但整个训练过程，这15%的Tokens一旦被选择就不再改变。</p><p>RoBERTa一开始把预训练的数据复制10份，每一份都随机选择15%的Tokens进行Masking，也就是说，同样的一句话有10种不同的mask方式。然后每份数据都训练N&#x2F;10个epoch。这就相当于在这N个epoch的训练中，每个序列的被mask的tokens是会变化的。</p><p><img src="/2023/01/10/LanguageModels/image-20230109234012371.png" alt="静态 Masking vs 动态 Masking"></p><h5 id="with-NSP-vs-without-NSP"><a href="#with-NSP-vs-without-NSP" class="headerlink" title="with NSP vs without NSP"></a>with NSP vs without NSP</h5><p>RoBERTa去除了NSP，而是每次输入连续的多个句子，直到最大长度512（可以跨文章）。这种训练方式叫做（FULL - SENTENCES），而原来的Bert每次只输入两个句子。实验表明在MNLI这种推断句子关系的任务上RoBERTa也能有更好性能。</p><p><img src="/2023/01/10/LanguageModels/image-20230109234442993.png" alt="with NSP vs without NSP"></p><h5 id="更大的mini-batch"><a href="#更大的mini-batch" class="headerlink" title="更大的mini-batch"></a>更大的mini-batch</h5><p>原本的 BERTbase 的batch size是256，训练 1M 个steps。RoBERTa 的 batch size 为 8k。作者借鉴了在机器翻译中，用更大的batch size配合更大学习率能提升模型优化速率和模型性能的现象，并且也用实验证明了确实Bert还能用更大的batch size。</p><p><img src="/2023/01/10/LanguageModels/image-20230109235207656.png" alt="更大的mini-batch"></p><h5 id="更多的数据，更长时间的训练"><a href="#更多的数据，更长时间的训练" class="headerlink" title="更多的数据，更长时间的训练"></a>更多的数据，更长时间的训练</h5><p>借鉴 XLNet 用了比 Bert 多10倍的数据，RoBERTa也用了更多的数据，配合更长时间的训练，性能再次提高。</p><p><img src="/2023/01/10/LanguageModels/image-20230109235356087.png" alt="更多的数据，更长时间的训练"></p><h2 id="GPT-系列"><a href="#GPT-系列" class="headerlink" title="GPT 系列"></a>GPT 系列</h2><p>Generative Pre-trained Transformer（GPT）系列是由 OpenAI 提出的一系列非常强大的预训练语言模型。</p><p>GPT模型的训练需要超大的训练语料，超多的模型参数以及超强的计算资源。GPT系列的模型结构秉承了不断堆叠transformer的思想，通过不断的提升训练语料的规模和质量，提升网络的参数数量来完成GPT系列的迭代更新的。GPT也证明了，通过不断的提升模型容量和语料规模，模型的能力是可以不断提升的。</p><p><img src="/2023/01/10/LanguageModels/image-20230110090210989.png" alt="GPT系列"></p><h4 id="GPT-1"><a href="#GPT-1" class="headerlink" title="GPT-1"></a>GPT-1</h4><h5 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h5><p>在 GPT-1 之前，传统的 NLP 模型往往使用大量的数据对有监督的模型进行任务相关的模型训练，而有监督学习的任务存在两个缺点：</p><ol><li>需要大量的标注数据，高质量的标注数据往往很难获得，因为在很多任务中，图像的标签并不是唯一的或者实例标签并不存在明确的边界；</li><li>根据一个任务训练的模型很难泛化到其它任务中，这个模型只能叫做“领域专家”而不是真正的理解了NLP。</li></ol><h5 id="思想-1"><a href="#思想-1" class="headerlink" title="思想"></a>思想</h5><p>先通过在无标签的数据上学习一个生成式的语言模型，然后再根据特定的任务进行微调，即无监督的预训练+有监督的模型微调。</p><h5 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h5><p><img src="/2023/01/10/LanguageModels/image-20230110101334539.png" alt="GPT-1"></p><ul><li>分类任务：将起始和终止token加入到原始序列两端，输入transformer中得到特征向量，最后经过一个全连接得到预测的概率分布；</li><li>自然语言推理：将前提（premise）和假设（hypothesis）通过分隔符（Delimiter）隔开，两端加上起始和终止token。再依次通过transformer和全连接得到预测结果；</li><li>语义相似度：输入的两个句子，正向和反向各拼接一次，然后分别输入给transformer，得到的特征向量拼接后再送给全连接得到预测结果；</li><li>问答和常识推理：将 n 个选项的问题抽象化为 n 个二分类问题，即每个选项分别和内容进行拼接，然后各送入transformer和全连接中，最后选择置信度最高的作为预测结果。</li></ul><h5 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h5><p>GPT-1使用了 BooksCorpus 数据集，这个数据集包含 7,000 本没有发布的书籍。作者选这个数据集的原因有二：1. 数据集拥有更长的上下文依赖关系，使得模型能学得更长期的依赖关系；2. 这些书籍因为没有发布，所以很难在下游数据集上见到，更能验证模型的泛化能力。</p><h4 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h4><p>GPT-2的目标旨在训练一个泛化能力更强的词向量模型，它并没有对GPT-1的网络进行过多的结构的创新与设计，只是使用了更多的网络参数和更大的数据集。</p><h5 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h5><p>作者认为，当一个语言模型的容量足够大时，它就足以覆盖所有的有监督任务，也就是说，任何有监督任务都是语言模型的一个子集，当模型的容量非常大且数据量足够丰富时，仅仅靠训练语言模型的学习便可以完成其他有监督学习的任务。</p><h5 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h5><p>GPT-2 的文章取自于 Reddit 上高赞的文章，命名为 WebText。数据集共有约800万篇文章，累计体积约 40G。为了避免和测试集的冲突，WebText 移除了涉及 Wikipedia 的文章。</p><h5 id="贡献-1"><a href="#贡献-1" class="headerlink" title="贡献"></a>贡献</h5><p>验证了通过海量数据和大量参数训练出来的词向量模型有迁移到其它类别任务中而不需要额外的训练的能力。</p><h4 id="GPT-3"><a href="#GPT-3" class="headerlink" title="GPT-3"></a>GPT-3</h4><p>强大：仅仅需要zero-shot或者few-shot，就可以在下游任务表现的非常好。</p><p>巨巨巨烧钱：1750亿的参数，31个分工明确的作者，超强算力的计算机（ 285,000 个CPU， 10,000 个 GPU），1200万的训练费用，45TB 的训练数据（维基百科的全部数据只相当于其中的 0.6% ）。</p><h5 id="meta-learning（元学习）"><a href="#meta-learning（元学习）" class="headerlink" title="meta-learning（元学习）"></a>meta-learning（元学习）</h5><p>对于一个少样本的任务来说，模型的初始化值非常重要，从一个好的初始化值作为起点，模型能够更快收敛。</p><p>元学习的核心思想在于通过少量的数据寻找一个合适的初始化范围，使得模型能够在有限的数据集上快速拟合，并获得不错的效果。</p><h5 id="In-context-learning（情境学习）"><a href="#In-context-learning（情境学习）" class="headerlink" title="In-context learning（情境学习）"></a>In-context learning（情境学习）</h5><p><img src="/2023/01/10/LanguageModels/image-20230110121446447.png" alt="In-context learning"></p><h5 id="Without-fine-tuning"><a href="#Without-fine-tuning" class="headerlink" title="Without fine-tuning"></a>Without fine-tuning</h5><p>从理论上讲GPT-3也是支持fine-tuning的，但是fine-tuning需要利用海量的标注数据进行训练才能获得比较好的效果，但是这样也会造成对其它未训练过的任务上表现差，所以GPT-3并没有尝试fine-tuning。</p><h5 id="模型容量"><a href="#模型容量" class="headerlink" title="模型容量"></a>模型容量</h5><p>实验结果表明，三个学习方式的效果都会随着模型容量的上升而上升，且few shot &gt; one shot &gt; zero shot。</p><p><img src="/2023/01/10/LanguageModels/image-20230110125804638.png" alt="容量upup，准确率upup"></p><h5 id="数据集-2"><a href="#数据集-2" class="headerlink" title="数据集"></a>数据集</h5><p>GPT-3共训练了5个不同的语料，分别是低质量的Common Crawl，高质量的 WebText2，Books1，Books2 和 Wikipedia，GPT-3根据数据集的不同的质量赋予了不同的权值，权值越高的在训练的时候越容易抽样到。</p><p><img src="/2023/01/10/LanguageModels/image-20230110130508351.png" alt="不同数据集对应的结果"></p><h5 id="结构-2"><a href="#结构-2" class="headerlink" title="结构"></a>结构</h5><p>GPT-3沿用了GPT-2的结构，但是在网络容量上做了很大的提升，如采用了96层的多头 transformer。</p><h5 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h5><ol><li>对于一些命题没有意义的问题，GPT-3不会判断命题有效与否，而是拟合一个没有意义的答案出来；</li><li>由于 40TB 海量数据的存在，很难保证GPT-3生成的文章不包含一些非常敏感的内容，例如种族歧视，性别歧视，宗教偏见等；</li><li>受限于transformer的建模能力，GPT-3并不能保证生成的一篇长文章或者一本书籍的连贯性，存在下文不停重复上文的问题。</li></ol><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>GPT 系列从1到3，通通采用的是 transformer 架构，可以说模型结构并没有创新性的设计。</p><p>本质是通过海量的参数学习海量的数据，然后依赖transformer强大的拟合能力使得模型能够收敛。</p><h2 id="野生-GPT-系列"><a href="#野生-GPT-系列" class="headerlink" title="野生 GPT 系列"></a>野生 GPT 系列</h2><p>为了打破 OpenAI 和微软对自然语言处理 AI 模型的垄断，EleutherAI 研究并开源了一系列可以与类似规模的 GPT-3 模型相媲美的自然语言处理 AI 模型。</p><h4 id="GPT-Neo"><a href="#GPT-Neo" class="headerlink" title="GPT-Neo"></a>GPT-Neo</h4><p>EleutherAI 在 2021 年 3 月发布了 27 亿参数的 GPT-Neo 模型，这是他们对类 GPT 系统的第一个实现。GPT-Neo 是在 TensorFlow 中构建的，并通过 Mesh TensorFlow 并行库在 TPU 上训练。</p><p>模型参数级别：125 M，350 M，1.3 B，2.7 B。</p><p>GPT-Neo 开源模型里较大的版本也只达到了 GPT-3 商用版里最小模型的参数量。</p><p>训练效率低 + GPU 资源变多 → GPT-NeoX。</p><h4 id="GPT-J"><a href="#GPT-J" class="headerlink" title="GPT-J"></a>GPT-J</h4><p>GPT-J 是一个基于 GPT-3、由 60 亿个参数组成的自然语言处理 AI 模型。该模型在一个 800 GB 的开源文本数据集上进行训练，能够与类似规模的 GPT-3 模型相媲美。</p><p>GPT-J 使用新库 Mesh-Transformer-JAX 来训练，该库没有使用像 TensorFlow 这样的特定深度学习框架，而是使用 Google 的 JAX 线性代数框架。</p><p>与 GPT-Neo 模型相比，GPT-J 的训练效率提高了 125%。在几个 Down-Streaming 工作负载的零点性能方面，GPT-J 是公开的 Transformer LM 中表现最好的。</p><h4 id="GPT-NeoX"><a href="#GPT-NeoX" class="headerlink" title="GPT-NeoX"></a>GPT-NeoX</h4><h5 id="The-Pile"><a href="#The-Pile" class="headerlink" title="The Pile"></a>The Pile</h5><p>这是一个 825 GB 的用于训练的多样化文本数据集。The Pile 由 22 个不同的高质量子集构成，包括现有的和新建的，其中许多来源于学术领域或各专业领域。</p><h5 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h5><p>此前，在 GPT-Neo 和 GPT-J 的训练过程中，EleutherAI 都是通过 TPU Research Cloud (TRC) 访问抢占式 TPU，但想在合理的时间内用 TRC TPU 训练超过数百亿参数的模型是不现实的。</p><p>2021 年 1 月，EleutherAI 宣布与 CoreWeave 达成合作，CoreWeave 承诺为 GPT-NeoX-20B 模型训练提供 GPU 资源。研究者透露，他们在 96 个 A100 上完成了 GPT-NeoX-20B 的训练，训练成本约 86 万美元。</p><h5 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h5><p>GPT-NeoX-20B 总体优于 GPT-J-6B 等，但和 DaVinci 相比还存在一定差距。</p><p><img src="/2023/01/10/LanguageModels/image-20230110145614826.png" alt="GPT-NeoX的表现"></p><h4 id="minGPT"><a href="#minGPT" class="headerlink" title="minGPT"></a>minGPT</h4><p><img src="/2023/01/10/LanguageModels/image-20230110150224995.png" alt="如果将GPT比作军舰，那么minGPT就像一艘快艇"></p><p>使用 PyTorch 对 GPT 的重新实现，包括训练和推断。minGPT 试图变得小、干净、可解释和有教育意义，因为目前大多数可用的GPT模型实现可能有点杂乱。minGPT 只有大约300行代码。所要做的就是将一个索引序列输入到一个Transformer中，然后该序列中下一个索引的概率分布出来。作者指出，GPT 中大多数的复杂性只是为了提高效率而巧妙地处理批处理。</p><h2 id="自然语言-编程语言预训练模型（NL-PL）"><a href="#自然语言-编程语言预训练模型（NL-PL）" class="headerlink" title="自然语言-编程语言预训练模型（NL-PL）"></a>自然语言-编程语言预训练模型（NL-PL）</h2><h4 id="CodeBERT"><a href="#CodeBERT" class="headerlink" title="CodeBERT"></a>CodeBERT</h4><p>将BERT应用到了Python、PHP、Java、JavaScript、Go、Ruby等编程语言的代码搜索和生成任务当中。</p><h5 id="自然语言搜索代码"><a href="#自然语言搜索代码" class="headerlink" title="自然语言搜索代码"></a>自然语言搜索代码</h5><p>通过自然语言query查找到所需的代码块的实现和搜索引擎（通过自然语言query来查找所需网页）类似。</p><p>作者在 CodeSearchNet 语料库上对CodeBERT进行了预训练并做微调，这是一个包含了 6 种较为普遍的代码语言（分别为Ruby、JavaScript、Go、Python、Java、PHP）的语料库。最终，在自然语言代码搜索任务中取得了 SOTA 的结果。</p><p><img src="/2023/01/10/LanguageModels/image-20230110171057473.png" alt="自然语言搜索代码"></p><h5 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h5><p>CodeBERT抓住了自然语言和编程语言之间的语义联系。</p><p><img src="/2023/01/10/LanguageModels/image-20230110171336102.png" alt="自然语言生成代码"></p><h5 id="结构-3"><a href="#结构-3" class="headerlink" title="结构"></a>结构</h5><p>在模型的整体架构上，CodeBERT 并未脱离 BERT 和 Roberta 的思想。和大多数工作类似，作者使用了多层双向 Transformer。</p><p>在预训练阶段，总共设计了两部分输入，一个是自然语言文本，另一个是编程语言的代码。在模型训练的设计上，其主要包括两个目标：</p><ul><li>掩码语言建模（MLM）。将NL-PL对作为输入，随机为NL和PL选择位置进行掩码，然后用特殊的掩码Token进行替换。注意，掩码语言建模的任务是预测出被掩码的原始Token。</li><li>可替换Token检测（Replaced Token Detection (RTD)）。在这部分有两个数据生成器，分别是NL生成器和PL生成器，这两个生成器都用于随机掩码位置集（randomly masked positions）生成合理的备选方案。另外，还有一个学习生成器用来检测一个词是否为原词，其背后原理是一个二进制分类器。</li></ul><p><img src="/2023/01/10/LanguageModels/image-20230110171745068.png" alt="模型架构"></p><p>模型训练的最后一步是模型微调，具体操作是在NL-PL任务中使用不同的CodeBERT设置。例如在自然语言代码搜索中，会使用与预训练阶段相同的输入方式。而在代码到文本的生成中，使用编码器-解码器框架，并使用CodeBERT初始化生成模型的编码器。</p><h5 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h5><p>在C#语言上的测试结果：</p><p><img src="/2023/01/10/LanguageModels/image-20230110173002897.png" alt="用C#测试泛化能力"></p><p>从这个结果可以看出，相较于 RoBERTa，CodeBERT 能够更好地推广到其他编程语言。不过值得注意的是，模型的效果略低于code2seq，作者认为原因可能是 code2seq 在其抽象语法树中使用组合路径，而CodeBERT仅将原始代码作为输入。</p><h5 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h5><ol><li>首个大型的 NL-PL 预训练模型，且在自然语言代码搜索和代码文档生成两个任务中都达到了SOTA性能；</li><li>提出了一个混合学习目标，能够支持使用双模数据NL-PL，且能够很容易地应用到单模数据中（例如没有自然语言文本的编程代码）；</li><li>建立了一个用来研究 NL-PL 预训练模型的探测能力的数据集，方便了以后跟进的研究人员。</li></ol><h4 id="PyMT5"><a href="#PyMT5" class="headerlink" title="PyMT5"></a>PyMT5</h4><p>一个既可以从自然语言文档字符串（文档字符串）预测整个方法，又可以将代码总结为任何通用风格的文档字符串的单一模型。</p><h5 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h5><p>对2600万个 Python 方法和770万个 methoddocstring 对的大规模并行语料库进行了分析和建模，证明对于文档字符串和方法的生成，PyMT5优于类似大小的自动回归语言模型(GPT-2)。</p><h5 id="数据集-3"><a href="#数据集-3" class="headerlink" title="数据集"></a>数据集</h5><p>由 118k GITHUB 存储库组成，约 27 GB。</p><p>输入序列中的前导注释指示模型输出特征的特定组合，例如。“#target signature and body”指示 PyMT5 要预测签名和正文。</p><p><img src="/2023/01/10/LanguageModels/image-20230110181309905.png" alt="PyMT5"></p><h5 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h5><p><img src="/2023/01/10/LanguageModels/image-20230110182104513.png" alt="空格 → G"></p><p>Python 文件的空格替换为字符 G 进行标记，然后将标记的随机子序列替换为编号的掩码，并训练模型返回每个掩码后面跟着它所替换的标记。</p><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><h4 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h4><p>官方代码和预训练模型：<a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a></p><p>Google官方推荐的PyTorch BERB版本实现，可加载Google预训练的模型：<a href="https://github.com/huggingface/pytorch-pretrained-BERT">https://github.com/huggingface/pytorch-pretrained-BERT</a></p><h4 id="RoBERTa"><a href="#RoBERTa" class="headerlink" title="RoBERTa"></a>RoBERTa</h4><p>官方代码和预训练模型：<a href="https://github.com/facebookresearch/fairseq">https://github.com/facebookresearch/fairseq</a></p><p>中文预训练RoBERTa模型：<a href="https://github.com/brightmart/roberta_zh">https://github.com/brightmart/roberta_zh</a></p><h4 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h4><p>GPT-1：<a href="https://github.com/huggingface/pytorch-openai-transformer-lm">https://github.com/huggingface/pytorch-openai-transformer-lm</a></p><p>GPT-2：<a href="https://github.com/openai/gpt-2">https://github.com/openai/gpt-2</a></p><p>GPT-3 API：<a href="https://openai.com/blog/api-no-waitlist/">https://openai.com/blog/api-no-waitlist/</a> ，需要海外手机号注册</p><p>GPT-Neo：<a href="https://github.com/EleutherAI/gpt-neo/">https://github.com/EleutherAI/gpt-neo/</a></p><p>GPT-J：<a href="https://github.com/kingoflolz/mesh-transformer-jax">https://github.com/kingoflolz/mesh-transformer-jax</a></p><p>GPT-NeoX：<a href="https://github.com/EleutherAI/gpt-neox/">https://github.com/EleutherAI/gpt-neox/</a></p><p>GPT-NeoX 试用：<a href="https://goose.ai/">https://goose.ai/</a></p><p>minGPT：<a href="https://github.com/karpathy/minGPT">https://github.com/karpathy/minGPT</a></p><h4 id="NL-PL"><a href="#NL-PL" class="headerlink" title="NL-PL"></a>NL-PL</h4><p>CodeBERT：<a href="https://github.com/microsoft/CodeBERT">https://github.com/microsoft/CodeBERT</a></p>]]></content>
    
    
    <categories>
      
      <category>IDEAS Lab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
      <tag>大模型学习笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022-2023跨年记</title>
    <link href="/2023/01/01/2022blog/"/>
    <url>/2023/01/01/2022blog/</url>
    
    <content type="html"><![CDATA[<h4 id="很奇怪"><a href="#很奇怪" class="headerlink" title="很奇怪"></a>很奇怪</h4><p>没什么感觉的跨年……之前每每跨年时，都会感觉有好多话想说，有种写年度总结然后发出来的冲动，但今年（或者用去年更合适，但想来还是用今年更舒服，这里就当今年还是2022吧）不太一样，今年完全没什么跨年的特殊感觉，只是单纯觉得又一年过去了仅此而已，我甚至没意识到是跨年，零点时收到朋友们的跨年祝福才想起已经2023了（里面竟然有几年没说过话的前前女友的祝福，乐），可能是因为今年跨年在家，睡得早了些吧 : ) 。</p><p>但又很奇怪的是，之前感概颇深，却没有一次真的发出年度总结（甚至没写），这次没什么感觉，此时此刻却正在写年度总结……想来大抵是因为之前没有建博客，想发就只能发到空间和朋友圈，而我又是对空间or朋友圈有些抵触的——大概就是，觉得想分享的事，朋友早就告诉过了，不熟的也没有必要告诉，又觉得空间就是展现自己的，而从某些事后我变得对自己缺乏自信，也就不想发空间了。</p><h4 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h4><p>总的来说，这一年过的并不好。</p><p>前半年，我过于沉浸虚拟世界之中，追求一些虚拟的荣誉（倒是也确实取得了一些，但那些又有什么用呢，哈哈哈），与之相伴的就是现实世界的事儿草草应付，整个大二下学期的作业都是临ddl才做，有时候赶不完，就找些资料cv了，考试也是考前几天猛补进度，基本上学一遍就去考试了，最后的成绩也想当然的低。唉，当时竟然还觉得无所谓……</p><p>但也幸好，这种情况到了大三有所改善，我退坑了之前的游戏，这种重新感受现实世界的感觉还不错。这学期的作业都基本都是提前做，大作业和实验也基本保证了独立完成，当然有不会的还是得请教各位佬。这种靠自己的感觉帮助我找回了一些自信，我发现有些之前觉得难于登天的科目，其实不过如此，是我之前没学就尝试做题，从什么不懂的视角来看，才看的一头雾水 : ( ，哈哈，有点搞笑。之前觉得枯燥的科目竟然也变得生动有趣起来，我有些后悔没有认真钻研之前的科目，同时也庆幸考试延期，有了更多时间来学习当下的科目。我竟然重新变得对学习有兴趣了？乐，希望这种状态能持续下去。</p><p>感觉这半年的心态也发生了一些变化吧，我似乎变得冷漠了很多，不再像之前一样时刻关注周围人的情绪，但这样更多把关注点放在自己身上，倒让我感觉舒服很多并想继续这样下去。</p><p>不过我似乎也一直是个冷漠的人，不然也不会在2022年将w从身边推走吧。</p><h4 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h4><p>希望2023能在实验室做出点东西来，然后夏令营能有一个好去向吧。</p><p>也希望能找回过去的自己。</p><h4 id="end"><a href="#end" class="headerlink" title="end"></a>end</h4><p>就先写这么多吧，想到哪儿写到哪儿，有些乱。</p>]]></content>
    
    
    <categories>
      
      <category>personal</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂谈</tag>
      
      <tag>跨年</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab7-2 Wireshark-HTTP</title>
    <link href="/2022/12/29/CNLab7-2/"/>
    <url>/2022/12/29/CNLab7-2/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab7-2-HTTP"><a href="#Lab7-2-HTTP" class="headerlink" title="Lab7-2 HTTP"></a>Lab7-2 HTTP</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>通过实验了解HTTP(超文本传输协议)的主要信息。HTTP是Web的主要协议。</p><h4 id="2-Steps"><a href="#2-Steps" class="headerlink" title="2 Steps"></a>2 Steps</h4><h5 id="Step-1-Capture-a-Trace"><a href="#Step-1-Capture-a-Trace" class="headerlink" title="Step 1: Capture a Trace"></a>Step 1: Capture a Trace</h5><p>实验手册中提供了本实验的抓包结果，可以直接点击<a href="https://kevincurran.org/com320/labs/wireshark/trace-http.pcap">链接</a>下载。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203071853706.png" alt="image-20221203071853706"></p><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>我们可以在应用显示过滤器中输入http来只查看http请求或响应包。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203071048252.png" alt="image-20221203071048252"></p><p>选择第一个HTTP请求包并展开它的HTTP块，查看其详细信息：</p><p><img src="/2022/12/29/CNLab7-2/image-20221203071930276.png" alt="image-20221203071930276"></p><ul><li>“Host”是一个必须有的头部，它标识了服务器的名称（和端口）。</li><li>“User-Agent”描述了浏览器的类型及其功能。</li><li>“Accept”、”Accept-Encoding”、”Accept-Charset”和”Accept-Language”对应了响应中接受的格式的描述。</li><li>“Cookie”是浏览器为网站保存的cookie的名称和值。</li><li>“Cache-Control”描述了如何缓存响应。</li></ul><p>选择与第一个HTTP请求包对应的HTTP响应包并展开它的HTTP块，查看其详细信息：</p><p><img src="/2022/12/29/CNLab7-2/image-20221203072659127.png" alt="image-20221203072659127"></p><ul><li>“Server”描述了服务器的类型及其功能。</li><li>“Date”和”Last-Modified”描述了响应的时间和内容最后更改的时间。</li><li>“Cache-Control”、”Expires”和”Etag”是关于如何缓存响应的信息。</li></ul><p><em>What is the format of a header line? Give a simple description that fits the headers you see.</em></p><p><em>对HTTP请求来说，header line由请求方法字段、URL字段和HTTP协议版本字段3个字段组成，它们用空格分隔。</em></p><p><img src="/2022/12/29/CNLab7-2/image-20221203073404456.png" alt="image-20221203073404456"></p><p><em>对HTTP响应来说，header line由服务器HTTP协议版本、服务器发回的响应状态代码和状态代码的文本描述3个字段组成，它们用空格分隔。</em></p><p><img src="/2022/12/29/CNLab7-2/image-20221203073418051.png" alt="image-20221203073418051"></p><p><em>What headers are used to indicate the kind and length of content that is returned in a response?</em></p><p><em>如图，为”Content-Type”和”Content-Length”。</em></p><p><img src="/2022/12/29/CNLab7-2/image-20221203074148726.png" alt="image-20221203074148726"></p><h5 id="Step-3-Content-Caching"><a href="#Step-3-Content-Caching" class="headerlink" title="Step 3: Content Caching"></a>Step 3: Content Caching</h5><p>通过查看抓包结果我们可以发现，抓包结果中的第二个GET包应该是第一个URL的重新获取。这为我们提供了一个查看缓存操作的机会，因为很有可能图像或文档没有更改，因此不需要再次下载，HTTP缓存机制应该能够识别这种机会。现在我们来看看它们是如何工作的。</p><p>选择第一个GET的重新获取的GET，并展开它的HTTP块。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203075022337.png" alt="image-20221203075022337"></p><p>现在找到让服务器判断是否需要发送新内容的报头。只有当内容自浏览器上次下载后发生了更改时，服务器才需要发送新内容。为了解决这个问题，浏览器包含一个时间戳，从上一次下载中获取它缓存的内容。这个头没有出现在第一个GET包中，因为我们清除了浏览器缓存，所以浏览器没有以前下载的可以使用的内容。在大多数其他方面，这个请求将与第一次请求相同。</p><p>最后，选择要重新获取的响应包，并查看它的HTTP块。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203080007795.png" alt="image-20221203080007795"></p><p>假设缓存按预期工作，此响应将不包含内容。相反，响应的状态代码将是“304 Not Modified”。这将告诉浏览器，内容与以前的副本没有变化，然后可以显示缓存的内容。</p><p><em>What is the name of the header the browser sends to let the server work out whether to send  fresh content?</em></p><p><em>这个报头叫做”If - Modified - Since”，也就是说，它要求服务器发送自给定时间以来是否被修改过的内容(如下图)。</em></p><p><img src="/2022/12/29/CNLab7-2/image-20221203075508047.png" alt="image-20221203075508047"></p><p><em>Where exactly does the timestamp value carried by the header come from?</em></p><p><em>时间戳值来自最近下载的内容的“Last-Modified”报头。</em></p><h5 id="Step-4-Complex-Pages"><a href="#Step-4-Complex-Pages" class="headerlink" title="Step 4: Complex Pages"></a>Step 4: Complex Pages</h5><p>现在我们将检查第四个HTTP请求（实验手册中说第三个，但第三个是”&#x2F;favicon.ico”的GET，这是浏览器请求站点的图标作为浏览器显示的一部分）。这种获取方法适用于更复杂的web页面，其中可能包含嵌入式资源。因此，浏览器将下载初始HTML加上渲染页面所需的所有嵌入式资源，再加上执行页面脚本期间请求的其他资源。正如我们将看到的，单个页面可以涉及多个GET。</p><p>我们可以通过打开一个”统计-HTTP”中的负载分配面板来总结本页的GET，查看这个面板将显示本机向哪些服务器发出了多少请求。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203081819906.png" alt="image-20221203081819906"></p><p>我们也可以通过打开一个”统计-HTTP”中的分组计数器面板来总结本页的GET，这个面板显示了请求和响应的类型。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203082001645.png" alt="image-20221203082001645"></p><p>可以使用一个网站如谷歌的<a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed</a>或<a href="https://www.webpagetest.org/">ebpagetest.org</a>来更详细地了解整个页面加载过程。这些网站将测试已选择的URL，并生成页面加载活动的报告，显示在什么时间获取了什么请求，并给出减少整体页面加载时间的提示。</p><p><a href="https://pagespeed.web.dev/report?url=https://www.bilibili.com/&form_factor=desktop">使用PageSpeed对B站测试</a>。</p><p><img src="/2022/12/29/CNLab7-2/image-20221203083434334.png" alt="image-20221203083434334"></p><p><a href="https://www.webpagetest.org/result/221203_AiDc70_9B/">使用ebpagetest.org对泰山学堂官网进行测试</a>。</p><p>得到的瀑布图如下。</p><p><img src="/2022/12/29/CNLab7-2/image-20221229192032442.png" alt="image-20221229192032442"></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab7-1 Wireshark_DNS</title>
    <link href="/2022/12/29/CNLab7-1/"/>
    <url>/2022/12/29/CNLab7-1/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab7-1-DNS"><a href="#Lab7-1-DNS" class="headerlink" title="Lab7-1 DNS"></a>Lab7-1 DNS</h2><h4 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h4><p>域名系统(DNS)将主机名转换为IP地址，在互联网基础设施中发挥着关键作用。</p><h4 id="2-Steps"><a href="#2-Steps" class="headerlink" title="2 Steps"></a>2 Steps</h4><h5 id="Step-1-nslookup"><a href="#Step-1-nslookup" class="headerlink" title="Step 1: nslookup"></a>Step 1: nslookup</h5><p>简单介绍几种常用的nslookup命令：</p><ul><li><p>“nslookup <a href="http://www.mit.edu",意为“请给我发送主机www.mit.edu的ip地址”./">www.mit.edu&quot;，意为“请给我发送主机www.mit.edu的IP地址”。</a></p><p><img src="/2022/12/29/CNLab7-1/image-20221203000122497.png" alt="image-20221203000122497"></p></li><li><p>“nslookup –type&#x3D;NS mit.edu”，意为”请把mit.edu的权威DNS的主机名发给我“，当不使用-type选项时，nslookup使用默认值，即查询A类型的记录。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203000137389.png" alt="image-20221203000137389"></p></li><li><p>“nslookup <a href="http://www.aiit.or.kr/">www.aiit.or.kr</a> bitsy.mit.edu”，使用这个命令，我们将会将查询发送到DNS服务器bitsy.mit.edu，而不是缺省DNS服务器(DNS -prime.poly.edu)，即查询和回复直接发生在我们的查询主机和bitsy.mit.edu之间。</p><p>这里一直显示超时，估计是地域原因（主机<a href="http://www.aiit.or.kr是韩国高级信息技术学院的web服务器)./">www.aiit.or.kr是韩国高级信息技术学院的web服务器）。</a></p><p><img src="/2022/12/29/CNLab7-1/image-20221203000222701.png" alt="image-20221203000222701"></p></li><li><p>“nslookup –option1 –option2 host-to-find dns-server”是nslookup的一般语法，我们可以看到，nslookup可以在0个、1个、2个或多个选项的情况下运行（dns-server也是可选的）。</p></li></ul><p><em>1. Run nslookup to obtain the IP address of a Web server in Asia. What is the IP address of that server?</em> </p><p><em>如图，获取到”<a href="http://www.sdu.edu.cn"的IP地址为202.194.7.118（2001:da8:7000:7:202:194:7:118为IPv6地址）。">www.sdu.edu.cn&quot;的IP地址为202.194.7.118（2001:da8:7000:7:202:194:7:118为IPv6地址）。</a></em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203000744223.png" alt="image-20221203000744223"></p><p><em>2. Run nslookup to determine the authoritative DNS servers for a university in Europe.</em> </p><p><em>这里选择了剑桥大学。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203051444665.png" alt="image-20221203051444665"></p><p><em>3. Run nslookup so that one of the DNS servers obtained in Question 2 is queried for the mail servers for Yahoo! mail. What is its IP address?</em></p><p><em>如下图，这里试了很多个问题2中的DNS服务器都显示找不到，最后就查了剑桥大学来代替了。得到的IP地址为128.232.132.8。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203051742327.png" alt="image-20221203051742327"></p><h5 id="Step-2-ipconfig"><a href="#Step-2-ipconfig" class="headerlink" title="Step 2: ipconfig"></a>Step 2: ipconfig</h5><p>ipconfig可以用来显示当前的TCP&#x2F;IP信息，包括本机的地址、DNS服务器地址、适配器类型等，我们使用”ipconfig &#x2F;all”命令来获得以上提到的所有信息。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203052522889.png" alt="image-20221203052522889"></p><p>ipconfig对于管理存储在主机中的DNS信息也非常有用，比如我们可以使用”ipconfig &#x2F;displaydns”命令来查看主机缓存的最近获得的DNS记录。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203052837255.png" alt="image-20221203052837255"></p><p>我们也可以通过输入”ipconfig &#x2F;flushdns”命令来清除缓存。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203053019621.png" alt="image-20221203053019621"></p><p>Step 3: Tracing DNS with Wireshark</p><p>现在我们将通过Wireshark来追踪DNS。首先，使用”ipconfig &#x2F;flushdns”命令来清楚DNS缓存。然后在Wireshark中使用”ip.addr &#x3D;&#x3D; 192.168.254.245”（这里的192.168.56.1是本机IP地址）过滤器（这个过滤器将删除既不从本地主机发出也不发往本地主机的所有数据包）来开始抓包。最后，使用浏览器浏览一个网页，如这里实验手册提供的”<a href="http://www.ietf.org".抓包结果如下图./">http://www.ietf.org&quot;。抓包结果如下图。</a></p><p><img src="/2022/12/29/CNLab7-1/image-20221203054524747.png" alt="image-20221203054524747"></p><p><em>4. Locate the DNS query and response messages. Are then sent over UDP or TCP?</em>  </p><p><em>如下图，通过UDP发送。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203055016658.png" alt="image-20221203055016658"></p><p><em>5. What is the destination port for the DNS query message? What is the source port  of DNS response message?</em> </p><p><em>由下面两图可知，DNS查询消息的目的端口和DNS响应消息的源端口都为53。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203055905381.png" alt="image-20221203055905381"></p><p><img src="/2022/12/29/CNLab7-1/image-20221203055928083.png" alt="image-20221203055928083"></p><p><em>6. To what IP address is the DNS query message sent? Use ipconfig to determine the IP address of your local DNS server. Are these two IP addresses the same?</em>  </p><p><em>DNS查询消息发送到的IP地址为192.168.254.245，使用 ipconfig 确定的本地 DNS 服务器的 IP 地址也为192.168.254.245。对比可以发现，二者相同。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203055349865.png" alt="image-20221203055349865"></p><p><img src="/2022/12/29/CNLab7-1/image-20221203055330579.png" alt="image-20221203055330579"></p><p><em>7. Examine the DNS query message. What “Type” of DNS query is it? Does the  query message contain any “answers”?</em> </p><p><em>如下图，为A类型（也有AAAA类型），没有答案。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203060313173.png" alt="image-20221203060313173"></p><p><em>8. Examine the DNS response message. How many “answers” are provided? What  do each of these answers contain?</em></p><p><em>下面这个例子中，答案数为1，其内容如图。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203060550658.png" alt="image-20221203060550658"></p><p><em>9. Consider the subsequent TCP SYN packet sent by your host. Does the destination IP address of the SYN packet correspond to any of the IP addresses provided in the DNS response message?</em> </p><p><em>如下图可知，二者相对应。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203061017800.png" alt="image-20221203061017800"></p><p><em>10. This web page contains images. Before retrieving each image, does your host issue new DNS queries?</em> </p><p><em>发起了新的查询，原因可能是图片存放的服务器的域名和之前查询的不一致。</em></p><p>现在我们来练习使用nslookup。首先，先在命令行运行”ipconfig &#x2F;flushdns”以清除缓存。在打开Wireshark开始抓包后，在命令行中输入”nslookup on <a href="http://www.mit.edu"./">www.mit.edu&quot;。</a></p><p><img src="/2022/12/29/CNLab7-1/image-20221203062325456.png" alt="image-20221203062325456"></p><p>运行完成后停止抓包，得到结果如下图。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203062555017.png" alt="image-20221203062555017"></p><p><em>11. What is the destination port for the DNS query message? What is the source port  of DNS response message?</em> </p><p><em>由下面两图可知，与之前一样，DNS查询消息的目的端口和DNS响应消息的源端口都为53。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203062736314.png" alt="image-20221203062736314"></p><p><img src="/2022/12/29/CNLab7-1/image-20221203062834172.png" alt="image-20221203062834172"></p><p><em>12. To what IP address is the DNS query message sent? Is this the IP address of your default local DNS server?</em> </p><p><em>由下图可知，DNS 查询消息发送到的IP地址为192.168.254.245，这与我们之前得到的本地DNS服务器的IP地址相同。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203062950094.png" alt="image-20221203062950094"></p><p><em>13. Examine the DNS query message. What “Type” of DNS query is it? Does the  query message contain any “answers”?</em> </p><p><em>如下图，为A类型（也有AAAA类型），没有答案。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203063129764.png" alt="image-20221203063129764"></p><p><em>14. Examine the DNS response message. How many “answers” are provided? What do each of these answers contain?</em> </p><p><em>如下图，答案数为3，内容如图。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203063254661.png" alt="image-20221203063254661"></p><p><em>15. Provide a screenshot.</em></p><p><em>上面每个问题的回答都带有截图。</em></p><p>现在重复刚刚的实验，不过把命令换为”nslookup –type&#x3D;NS mit.edu”。抓包结果如下。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203064325190.png" alt="image-20221203064325190"></p><p><em>16. To what IP address is the DNS query message sent? Is this the IP address of your default local DNS server?</em> </p><p><em>由下图可知，DNS 查询消息发送到的IP地址为192.168.254.245，这与我们之前得到的本地DNS服务器的IP地址相同。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203064401955.png" alt="image-20221203064401955"></p><p><em>17. Examine the DNS query message. What “Type” of DNS query is it? Does the  query message contain any “answers”?</em> </p><p><em>如下图，为NS类型，没有答案。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203064459497.png" alt="image-20221203064459497"></p><p><em>18. Examine the DNS response message. What MIT nameservers does the response message provide? Does this response message also provide the IP addresses of the MIT namesers?</em> </p><p><em>如图，提供了麻省理工学院的一系列nameserver。经比对可发现，响应消息里不包含麻省理工学院的IP地址。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203064921225.png" alt="image-20221203064921225"></p><p><em>19. Provide a screenshot.</em></p><p><em>上面每个问题的回答都带有截图。</em></p><p>再次重复刚刚的实验，不过把命令换为”nslookup <a href="http://www.google.com/">www.google.com</a> bitsy.mit.edu”（这里实验手册给出的命令为”nslookup <a href="http://www.aiit.or.kr/">www.aiit.or.kr</a> bitsy.mit.edu”，但一直超时（如下图），试了下最后发现改成谷歌可以）。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203065543303.png" alt="image-20221203065543303"></p><p>抓包结果如下。</p><p><img src="/2022/12/29/CNLab7-1/image-20221203065758030.png" alt="image-20221203065758030"></p><p><em>20. To what IP address is the DNS query message sent? Is this the IP address of your  default local DNS server? If not, what does the IP address correspond to?</em> </p><p><em>由下图可知，DNS 查询消息发送到的IP地址为18.0.72.3，这与我们之前得到的本地DNS服务器的IP地址不同，它对应的是bitsy.mit.edu。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203070205462.png" alt="image-20221203070205462"></p><p><em>21. Examine the DNS query message. What “Type” of DNS query is it? Does the  query message contain any “answers”?</em> </p><p><em>如下图，为A类型（也有AAAA类型），没有答案。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203070256432.png" alt="image-20221203070256432"></p><p><em>22. Examine the DNS response message. How many “answers” are provided? What  does each of these answers contain?</em> </p><p><em>如下图，答案数为1，内容如图。</em></p><p><img src="/2022/12/29/CNLab7-1/image-20221203070404563.png" alt="image-20221203070404563"></p><p><em>23. Provide a screenshot.</em></p><p><em>上面每个问题的回答都带有截图。</em></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab6-2 Wireshark-UDP</title>
    <link href="/2022/12/29/CNLab6-2/"/>
    <url>/2022/12/29/CNLab6-2/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab6-2-UDP"><a href="#Lab6-2-UDP" class="headerlink" title="Lab6-2 UDP"></a>Lab6-2 UDP</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>查看UDP(用户数据报协议)的详细信息。UDP是在Internet上使用的一种传输协议，在不需要可靠性时作为TCP的替代方案。</p><h4 id="2-Steps"><a href="#2-Steps" class="headerlink" title="2 Steps"></a>2 Steps</h4><h5 id="Step-1-Capture-a-Trace"><a href="#Step-1-Capture-a-Trace" class="headerlink" title="Step 1: Capture a Trace"></a>Step 1: Capture a Trace</h5><p>跟上个实验一样，实验手册中提供了本实验的抓包结果，可以直接点击<a href="https://kevincurran.org/com320/labs/wireshark/trace-udp.pcap">链接</a>下载。</p><p><img src="/2022/12/29/CNLab6-2/image-20221202220817270.png" alt="image-20221202220817270"></p><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>任选一个协议列为DNS的从服务端下载到本机的长数据包，查看其UDP协议层的详细信息。</p><p><img src="/2022/12/29/CNLab6-2/image-20221202220919216.png" alt="image-20221202220919216"></p><p>我们可以看到以下字段（我们只讨论通过网络传输的字段）：</p><ul><li>“Source Port”和”Destination Port”分别是UDP消息发送的端口号和UDP消息目的地的端口号。端口是UDP中唯一的寻址形式。</li><li>“Length”给出了UDP消息的长度。</li><li>“Checksum”是用于验证消息内容的消息校验和。</li></ul><h5 id="Step-3-UDP-Message-Structure"><a href="#Step-3-UDP-Message-Structure" class="headerlink" title="Step 3: UDP Message Structure"></a>Step 3: UDP Message Structure</h5><table><thead><tr><th>IP header</th><th>Source Port</th><th>Destination Port</th><th>Length</th><th>Checksum</th><th>UDP payload</th></tr></thead><tbody><tr><td></td><td>2 bytes</td><td>2 bytes</td><td>2 bytes</td><td>2 bytes</td><td></td></tr><tr><td></td><td>UDP header(8 bytes)</td><td>~</td><td>~</td><td>~</td><td></td></tr></tbody></table><p><em>1. What does the Length field include? The UDP payload, UDP payload and UDP header, or UDP  payload, UDP header, and lower layer headers?</em></p><p>Length字段给出了UDP有效负载字节加上UDP报头的长度。</p><p><em>2. How long in bits is the UDP checksum?</em> </p><p>校验和是16位长。</p><p><em>3. How long in bytes is the entire UDP header?</em></p><p>UDP头长度为8字节。</p><h5 id="Step-4-UDP-Usage"><a href="#Step-4-UDP-Usage" class="headerlink" title="Step 4: UDP Usage"></a>Step 4: UDP Usage</h5><p>为了加深我们对UDP的理解，我们将看看UDP在应用程序中作为一种传输协议是如何被实际使用的。</p><p>我们可以考虑几个问题，第一个问题是IP如何知道下一个更高的协议层是UDP，答案是在IP报头中有一个Protocol字段，它包含这个信息。</p><p><em>Q: Give the value of the IP Protocol field that identifies the upper layer protocol as UDP.</em></p><p><em>A：如下图，“IP Protocol”字段值为17表示UDP。</em></p><p><img src="/2022/12/29/CNLab6-2/image-20221202223719259.png" alt="image-20221202223719259"></p><p>第二个问题是UDP消息通常如何在IP层寻址。我们可以发现一个神奇的事情，就是UDP消息既不来自于本地计算机，也不是只发送到本地计算机，我们可以通过对Source和Destination列进行排序来查看这一点。这种情况的原因是UDP被广泛用作系统协议的一部分，这些协议经常使用广播和多播地址向所有对它们感兴趣的本地计算机发送消息。</p><p><em>Q: Examine the UDP messages and give the destination IP addresses that are used when your computer is neither the source IP address nor the destination IP address. (If you have only your computer as the source or destination IP address then you may use the supplied trace.)</em></p><p><em>A：如下图，此时目标IP地址为239.255.255.250。</em></p><p><img src="/2022/12/29/CNLab6-2/image-20221202224327032.png" alt="image-20221202224327032"></p><p><em>Q: What is the typical size of UDP messages in your trace?</em></p><p><em>我们依次查看各个数据包的UDP信息长度可以发现，这个答案会随着追踪变化。它们通常在100~200个字节之间。</em></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab6-1 Wireshark-TCP</title>
    <link href="/2022/12/29/CNLab6-1/"/>
    <url>/2022/12/29/CNLab6-1/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab6-1-TCP"><a href="#Lab6-1-TCP" class="headerlink" title="Lab6-1 TCP"></a>Lab6-1 TCP</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>查看TCP(传输控制协议)的详细信息。</p><h4 id="2-Requirements"><a href="#2-Requirements" class="headerlink" title="2 Requirements"></a>2 Requirements</h4><p>本实验要求使用Wireshark软件、wget程序和任意的web浏览器。</p><h4 id="3-Steps"><a href="#3-Steps" class="headerlink" title="3 Steps"></a>3 Steps</h4><h5 id="Step-1-Capture-a-Trace"><a href="#Step-1-Capture-a-Trace" class="headerlink" title="Step 1: Capture a Trace"></a>Step 1: Capture a Trace</h5><p>实验手册中提供了本实验的抓包结果，可以直接点击<a href="https://kevincurran.org/com320/labs/wireshark/trace-tcp.pcap">链接</a>下载（学校官网的链接无法下载，在凯文教授主页找到了可以下载的链接）。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202194107359.png" alt="image-20221202194107359"></p><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>任选一个协议列为TCP的从服务端下载到本机的长数据包，查看其TCP协议层的详细信息。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202195842295.png" alt="image-20221202195842295"></p><p>我们可以看到以下字段（我们只讨论通过网络传输的字段）：</p><ul><li>“Source Port”和”Destination Port”是TCP在IP地址之外添加的寻址。”Source Port”即源端口号很可能是80（这里也的确是80），这是因为数据包由web服务器发送，而标准的web服务器端口是80。</li><li>“Sequence Number”给出了第一个有效负载字节在字节流中的位置。</li><li>“Acknowledgment Number”给出了反向字节流中最后接受到的位置。</li><li>“Header Length”给出了TCP报头的长度。</li><li>“Flags”字段有多个标志位来表示TCP段的类型。</li><li>“Checksum”用于检测传输错误。</li><li>“Options”字段提供了一系列选项。</li><li>“TCP payload”字段存储了被传输的字节。</li></ul><h5 id="Step-3-TCP-Segment-Structure"><a href="#Step-3-TCP-Segment-Structure" class="headerlink" title="Step 3: TCP Segment Structure"></a>Step 3: TCP Segment Structure</h5><table><thead><tr><th>Source Port</th><th>Destination Port</th><th>Sequence number</th><th>Ack number</th><th>Header length</th><th>Flags</th><th>Check sum</th><th>Window size</th><th>Urgent pointer</th><th>Options</th><th>Payload</th></tr></thead><tbody><tr><td>2 bytes</td><td>2 bytes</td><td>4 bytes</td><td>4 bytes</td><td>(2</td><td>bytes)</td><td>2 bytes</td><td>2 bytes</td><td>2 bytes</td><td>variable</td><td>N bytes</td></tr><tr><td>TCP header</td><td>~</td><td>~</td><td>~</td><td>~</td><td>~</td><td>~</td><td>~</td><td>~</td><td>~</td><td>TCP payload</td></tr></tbody></table><h5 id="Step-4-TCP-Connection-Setup-x2F-Teardown"><a href="#Step-4-TCP-Connection-Setup-x2F-Teardown" class="headerlink" title="Step 4: TCP Connection Setup&#x2F;Teardown"></a>Step 4: TCP Connection Setup&#x2F;Teardown</h5><p>要查看“三次握手”的运行情况，请查找带有SYN标志的TCP段以及它后面的包，也可以使用过滤器表达式“tcp.flags.syn&#x3D;&#x3D;1”来搜索带有SYN标志的数据包。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202201920364.png" alt="image-20221202201920364"></p><p>“SYN”包是三次握手的开始。在它被从本机发送到远程服务器后，远程服务器应该返回一个“SYN,ACK”包。在接收到这个包后，本地计算机将对其进行确认并开始发送数据。</p><p><em>Draw a time sequence diagram of the three-way handshake in your trace, up to and including the first  data packet (the HTTP GET request) sent by your computer when the connection is established Put your  computer on the left side and the remote server on the right side. As usual, time runs down the page,  and lines across the page indicate segments.</em> </p><p><em>Include the following features on your diagram:</em> </p><ul><li><em>The Sequence and ACK number, if present, on each segment. The ACK number is only carried if  the segment has the ACK flag set.</em> </li><li><em>The time in milliseconds, starting at zero, each segment was sent or received at your computer.</em> </li><li><em>The round-trip time to the server estimated as the difference between the SYN and SYN-ACK  segments.</em></li></ul><p><img src="/2022/12/29/CNLab6-1/image-20221202202219889.png" alt="image-20221202202219889"></p><p>“SYN”包和”SYN,ACK”包及后续包（直至并包括连接建立时计算机发送的第一个数据包(HTTP GET请求)）如上图，参考上图可以画出三次握手的时间序列图。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202205820368.png" alt="image-20221202205820368"></p><h5 id="Step-5-Connection-Options"><a href="#Step-5-Connection-Options" class="headerlink" title="Step 5: Connection Options"></a>Step 5: Connection Options</h5><p>除了建立连接之外，TCP “SYN”包还使用选项在两端之间协商参数。每一端通过在其SYN上包含适当的选项向另一端描述其能力(如果有的话)，通常两端都必须支持在数据传输过程中用到的行为。</p><p><em>What TCP Options are carried on the SYN packets for your trace?</em></p><p>如下图。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202204643312.png" alt="image-20221202204643312"></p><h5 id="Step-6-FIN-x2F-RST-Teardown"><a href="#Step-6-FIN-x2F-RST-Teardown" class="headerlink" title="Step 6: FIN&#x2F;RST Teardown"></a>Step 6: FIN&#x2F;RST Teardown</h5><p>最后，TCP连接在下载完成后关闭，这通常通过FIN (Finalize)段来完成。每一方发送一个FIN给另一方，并确认他们收到的FIN，这有点类似于三次握手。或者，当一端发送RST (Reset)时，连接可能突然断开，这个数据包不需要被对方确认。</p><p><em>Draw a picture of the teardown in your trace, starting from when the first FIN or RST is issued until the  connection is complete. As before, show the sequence and ACK numbers on each segment. If you have  FINs then use the time difference to estimate the round-trip time.</em></p><p><img src="/2022/12/29/CNLab6-1/image-20221202205315973.png" alt="image-20221202205315973"></p><p>参考上图，可以画出时间序列图。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202210117925.png" alt="image-20221202210117925"></p><h5 id="Step-7-TCP-Data-Transfer"><a href="#Step-7-TCP-Data-Transfer" class="headerlink" title="Step 7: TCP Data Transfer"></a>Step 7: TCP Data Transfer</h5><p>在”统计“栏中选择”I&#x2F;O图表“，然后点击左下角”+”添加新图形，并修改”Display Filter”值分别为”tcp.srcport&#x3D;&#x3D;80”和”tcp.dstport=&#x3D;80”，得到下面的图表。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202212100606.png" alt="image-20221202212100606"></p><p><em>1. What is the rough data rate in the download direction in packets&#x2F;second and bits&#x2F;second once  the TCP connection is running well?</em></p><p>以包&#x2F;秒的单位的速率可以参考上图，可以看出速率约为225 包&#x2F;秒；以位&#x2F;秒的单位的速率可以参考下图，可以看出速率约为$2.5×10^6$ 位&#x2F;秒。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202213527791.png" alt="image-20221202213527791"></p><p><em>2. What percentage of this download rate is content? Show your calculation. To find out, look at a  typical download packet; there should be many similar, large download packets. You can see  how long it is, and how many bytes of TCP payload it contains.</em></p><p>由下图可知，下载总量为1434 bytes，其中有效负载总量为1368 bytes，比例约为95.40%（1368&#x2F;1434≈0.95397）。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202213924589.png" alt="image-20221202213924589"></p><p><em>3. What is the rough data rate in the upload direction in packets&#x2F;second and bits&#x2F;second due to the  ACK packets?</em></p><p>以包&#x2F;秒为单位的数据可以从第一张I&#x2F;O图中读到，可以看到约为110 包&#x2F;秒；以位&#x2F;秒为单位的数据可以从下图中读到，可以看到约为42000 位&#x2F;秒。</p><p><img src="/2022/12/29/CNLab6-1/image-20221202214215309.png" alt="image-20221202214215309"></p><p><em>4. If the most recently received TCP segment from the server has a sequence number of X, then  what ACK number does the next transmitted TCP segment carry?</em></p><p>X加上数据段中的TCP有效负载字节数。</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab5-2 Wireshark_ICMP</title>
    <link href="/2022/12/29/CNLab5-2/"/>
    <url>/2022/12/29/CNLab5-2/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab5-2-ICMP"><a href="#Lab5-2-ICMP" class="headerlink" title="Lab5-2 ICMP"></a>Lab5-2 ICMP</h2><h4 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h4><p>在这个实验中，我们将探索ICMP协议。</p><h4 id="2-Steps"><a href="#2-Steps" class="headerlink" title="2 Steps"></a>2 Steps</h4><h5 id="Step-1-ICMP-and-Ping"><a href="#Step-1-ICMP-and-Ping" class="headerlink" title="Step 1: ICMP and Ping"></a>Step 1: ICMP and Ping</h5><p>让我们从捕获Ping程序生成的数据包开始。首先使用Wireshark开始抓包（使用icmp过滤器），然后在命令行中输入”ping -n 10 <a href="http://www.ust.hk",待ping程序运行结束后停止抓包./">www.ust.hk&quot;，待ping程序运行结束后停止抓包。</a></p><p><img src="/2022/12/29/CNLab5-2/image-20221202071122623.png" alt="image-20221202071122623"></p><p>得到如下结果：</p><p><img src="/2022/12/29/CNLab5-2/image-20221202071452425.png" alt="image-20221202071452425"></p><p><em>1. What is the IP address of your host? What is the IP address of the destination host?</em>  </p><p>由下图可知，本机IP为172.25.145.196，目标主机IP为143.89.12.134。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202071856801.png" alt="image-20221202071856801"></p><p><em>2. Why is it that an ICMP packet does not have source and destination port numbers?</em> </p><p>因为ICMP是网络层的协议，它不需要传输层TCP或者UDP的承载，直接使用IP数据报承载，因此不需要源端口号和目的端口号，只要源地址和目的地址即可。</p><p><em>3. Examine one of the ping request packets sent by your host. What are the ICMP type and code numbers? What other fields does this ICMP packet have? How many bytes are the checksum, sequence number and identifier fields?</em> </p><p>由下图可知，Type值为8，Code值为0。这个ICMP包中还有校验和、标识符和序列号，各自占了两字节。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202072558910.png" alt="image-20221202072558910"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073132868.png" alt="image-20221202073132868"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073142828.png" alt="image-20221202073142828"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073148033.png" alt="image-20221202073148033"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073153547.png" alt="image-20221202073153547"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073159674.png" alt="image-20221202073159674"></p><p><em>4. Examine the corresponding ping reply packet. What are the ICMP type and code  numbers? What other fields does this ICMP packet have? How many bytes are the  checksum, sequence number and identifier fields?</em></p><p>由下图可知，Type值为0，Code值为0。这个ICMP包中还有校验和、标识符、序列号和响应时间，各自占了两字节。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202073421963.png" alt="image-20221202073421963"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073433230.png" alt="image-20221202073433230"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073438678.png" alt="image-20221202073438678"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073443351.png" alt="image-20221202073443351"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073448465.png" alt="image-20221202073448465"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202073459907.png" alt="image-20221202073459907"></p><h5 id="Step-2-ICMP-and-Traceroute"><a href="#Step-2-ICMP-and-Traceroute" class="headerlink" title="Step 2: ICMP and Traceroute"></a>Step 2: ICMP and Traceroute</h5><p>使用Wireshark开始抓包（使用icmp过滤器），然后在命令行中输入”tracert <a href="http://www.inria.fr",待程序运行结束后停止抓包./">www.inria.fr&quot;，待程序运行结束后停止抓包。</a></p><p><img src="/2022/12/29/CNLab5-2/image-20221202075312551.png" alt="image-20221202075312551"></p><p>得到如下结果：</p><p><img src="/2022/12/29/CNLab5-2/image-20221202075413742.png" alt="image-20221202075413742"></p><p><em>5. What is the IP address of your host? What is the IP address of the target  destination host?</em>  </p><p>由下图可知，本机IP为172.25.145.196，目标主机IP为128.93.162.83。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202075943982.png" alt="image-20221202075943982"></p><p><em>6. If ICMP sent UDP packets instead (as in Unix&#x2F;Linux), would the IP protocol number still be 01 for the probe packets? If not, what would it be?</em> </p><p>这里没有抓取到UDP包，查阅资料得知此时数据包的IP协议号不是 01，是17。</p><p><em>7. Examine the ICMP echo packet in your screenshot. Is this different from the ICMP ping query packets in the first half of this lab? If yes, how so?</em> </p><p>不同，前半部分的ping查询数据包中ICMP报文类型为11，表示数据报过期需要丢弃，返回此ICMP报文警告源主机。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202081111481.png" alt="image-20221202081111481"></p><p><em>8. Examine the ICMP error packet in your screenshot. It has more fields than the  ICMP echo packet. What is included in those fields?</em> </p><p>由对比可知，错误的数据包多了请求数据包内容。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202082019225.png" alt="image-20221202082019225"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202081811394.png" alt="image-20221202081811394"></p><p><em>9. Examine the last three ICMP packets received by the source host. How are these  packets different from the ICMP error packets? Why are they different?</em> </p><p>区别如上题所述，最后三个包正常收到了回复（感觉这里我抓包有问题，搜了搜看了下一些博主做的实验，发现他们有收到我没有收到的icmp包——Type值为3且标注了端点不可达）。</p><p><em>10. Within the tracert measurements, is there a link whose delay is significantly  longer than others? Refer to the screenshot in Figure 4, is there a link whose  delay is significantly longer than others? On the basis of the router names, can  you guess the location of the two routers on the end of this link?</em></p><p>由下图我们可以发现从第16次请求开始，花费时间一下子增长了很多。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202075312551.png" alt="image-20221202075312551"></p><p>使用<a href="https://ip.cn/ip/62.40.124.204.html">IP 地址查询</a>查询该IP可以发现其所在地理位置为英国。一直到第19个请求，IP所在的地理位置都为英国。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202083551548.png" alt="image-20221202083551548"></p><p>从第20个请求起的后续IP及目标主机IP所在的地理位置均在法国。</p><p><img src="/2022/12/29/CNLab5-2/image-20221202083815921.png" alt="image-20221202083815921"></p><p><img src="/2022/12/29/CNLab5-2/image-20221202083924132.png" alt="image-20221202083924132"></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab5-1 Wireshark-ipv4</title>
    <link href="/2022/12/29/CNLab5-1/"/>
    <url>/2022/12/29/CNLab5-1/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab5-1-IPv4"><a href="#Lab5-1-IPv4" class="headerlink" title="Lab5-1 IPv4"></a>Lab5-1 IPv4</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>了解IP (Internet Protocol)的详细信息。</p><h4 id="2-Requirements"><a href="#2-Requirements" class="headerlink" title="2 Requirements"></a>2 Requirements</h4><p>除Wireshark外，本实验要求使用wget和traceroute&#x2F;tracert程序。</p><h4 id="3-Steps"><a href="#3-Steps" class="headerlink" title="3 Steps"></a>3 Steps</h4><h5 id="Step-1-Capture-a-Trace"><a href="#Step-1-Capture-a-Trace" class="headerlink" title="Step 1: Capture a Trace"></a>Step 1: Capture a Trace</h5><ol><li><p>在远程服务器上选择一个URL，并使用wget获取内容，例如“wget <a href="https://www.uwa.edu.au/%E2%80%9D%E3%80%82">https://www.uwa.edu.au/”。</a></p><p><img src="/2022/12/29/CNLab5-1/image-20221202000104434.png" alt="image-20221202000104434"></p></li><li><p>执行到同一远程服务器的traceroute，以检查是否可以发现有关网络路径的信息。在Windows下执行“tracert <a href="http://www.uwa.edu.au”./">www.uwa.edu.au”。</a></p><p><img src="/2022/12/29/CNLab5-1/image-20221202001107868.png" alt="image-20221202001107868"></p></li><li><p>启动Wireshark并使用“tcp port 80”的过滤器开始捕获。确保勾选”enable network name resolution”。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202001438461.png" alt="image-20221202001438461"></p></li><li><p>在启动捕获之后，重复上面的wget命令，数据包就会被Wireshark记录下来。</p></li><li><p>命令执行完毕后，返回Wireshark，我们可以看到结果如下。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202002421546.png" alt="image-20221202002421546"></p></li></ol><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>选中任意一个数据包，查看它的IP报头的详细信息。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202002650580.png" alt="image-20221202002650580"></p><ul><li><p>“Version”为4，是”IPv4”的缘故。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202003359244.png" alt="image-20221202003359244"></p></li><li><p>“Header Length”描述了标题长度（可以发现”Version”和”Header Length”字段被打包进了一个字节中）。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202003406998.png" alt="image-20221202003406998"></p></li><li><p>“Differentiated Services Field”包含位标识，用来指示是否应该在路由器上以服务质量和拥塞指示来处理包。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202003329063.png" alt="image-20221202003329063"></p></li><li><p>“Total Length”字段顾名思义，描述了这部分信息的总长度。</p></li><li><p>“Identification”字段用于在一个大的IP包作为多个称为片段的小片段发送时对片段进行分组。</p></li><li><p>“Flags”和”Fragment Offset”字段，他们紧随”Identification”其后，也与片段有关。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202004037604.png" alt="image-20221202004037604"></p></li><li><p>“Time to Live（TTL）”和”Protocol”字段分别描述了持续时间和数据协议类型。</p></li><li><p>“Header Checksum”用来确保信息传输过程中的正确性，若校验和验证不正确，则会在丢弃掉对应的错误报文后再进行后续操作。</p></li><li><p>“Source Address”和”Destination Address”描述了源地址和目标地址。</p></li></ul><h5 id="Step-3-IP-Packet-Structure"><a href="#Step-3-IP-Packet-Structure" class="headerlink" title="Step 3: IP Packet Structure"></a>Step 3: IP Packet Structure</h5><p>用如下结构即可回答问题。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202004922050.png" alt="image-20221202004922050"></p><p><em>1. What are the IP addresses of your computer and the remote server?</em></p><p>本机IP：111.31.200.210；远程IP：172.25.145.196。</p><p><em>2. Does the Total Length field include the IP header plus IP payload, or just the IP payload?</em> </p><p>只包括IP payload。</p><p><em>3. How does the value of the Identification field change or stay the same for different packets? For  instance, does it hold the same value for all packets in a TCP connection or does it differ for each  packet? Is it the same in both directions? Can you see any pattern if the value does change?</em></p><p>一个连接中所有的包 Identification 都不相同，在不同方向上也不相同，在同一方向上每产生一个数据包会自增 1。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202010501507.png" alt="image-20221202010501507"></p><p><img src="/2022/12/29/CNLab5-1/image-20221202010511233.png" alt="image-20221202010511233"></p><p><em>4. What is the initial value of the TTL field for packets sent from your computer? Is it the maximum  possible value, or some lower value?</em> </p><p>128，不是最大值。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202010627509.png" alt="image-20221202010627509"></p><p><em>5. How can you tell from looking at a packet that it has not been fragmented? Most often IP packets in normal operation are not fragmented. But the receiver must have a way to be sure. Hint:  you may need to read your text to confirm a guess.</em> </p><p>如图，设置了”Don’t fragment”。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202010758745.png" alt="image-20221202010758745"></p><p><em>6. What is the length of the IP Header and how is this encoded in the header length field? Hint: notice that only 4 bits are used for this field, as the version takes up the other 4 bits of the byte. You may guess and check your text.</em></p><p>如图即可得知长度为20 bytes，编码为0x45。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202011016220.png" alt="image-20221202011016220"></p><h5 id="Step-4-Internet-Paths"><a href="#Step-4-Internet-Paths" class="headerlink" title="Step 4: Internet Paths"></a>Step 4: Internet Paths</h5><p>tracert输出通常打印每行一跳的信息，包括测量的往返时间和路由器的IP地址和DNS名称。DNS名称便于确定路由器所属的组织。由于tracert利用了通用路由器实现，所以不能保证它对路径上的所有路由器都有效，当它对路径的某些部分失败时，通常会看到“*”响应。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202001107868.png" alt="image-20221202001107868"></p><h5 id="Step-5-IP-Header-Checksum"><a href="#Step-5-IP-Header-Checksum" class="headerlink" title="Step 5: IP Header Checksum"></a>Step 5: IP Header Checksum</h5><p>我们可以通过验证包来探究IP报头校验和计算。首先，选择一个IP报头为20字节的包（这是没有选项时的最小报头大小，可以使这个练习更容易），然后按照以下步骤检查校验和值是否正确：</p><p><img src="/2022/12/29/CNLab5-1/image-20221202063248656.png" alt="image-20221202063248656"></p><ol><li><p>将内容分成10个两个字节(16位)的单词。每个单词将是4个十六进制数字，如这里的第一个单词是”45 00”。</p></li><li><p>使用常规加法将这10个单词相加。这里经加和后得到结果为4486b。</p></li><li><p>从结果中计算1s的补和，取任何前导数字(大于单词大小的4位数)并将它们加回到余数中。如在这里，4486b将变为486b+4&#x3D;486f。</p></li><li><p>最终的结果若为Oxffff，则说明验证为正确。这里我们得到的结果为0x486f，不是0xffff，说明验证为不正确。我们可以通过Wireshark来验证我们的计算结果：</p><ol><li><p>在”编辑-首选项-Protocols”中找到IPv4项并打开。</p></li><li><p>勾选”Validate the IPv4 checksum if possible”。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202064645772.png" alt="image-20221202064645772"></p></li><li><p>可以看到，刚刚选中的数据包的校验和果然是错误的。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202064841190.png" alt="image-20221202064841190"></p></li></ol></li><li><p>（为了有一次验证正确的经历）我们可以重新选一个包来计算，如Wireshark已显示校验和正确的21号包。我们划分单词后可以求得其和为3fffc，将进位加到低位得：fffc+3&#x3D;ffff，即最后得到的结果为0xffff，验证正确。</p><p><img src="/2022/12/29/CNLab5-1/image-20221202065220331.png" alt="image-20221202065220331"></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab4-2 Wireshark-80211</title>
    <link href="/2022/12/29/CNLab4-2/"/>
    <url>/2022/12/29/CNLab4-2/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab4-2-802-11"><a href="#Lab4-2-802-11" class="headerlink" title="Lab4-2 802.11"></a>Lab4-2 802.11</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>探究802.11的物理层、链路层和管理功能。</p><h4 id="2-Requirements"><a href="#2-Requirements" class="headerlink" title="2 Requirements"></a>2 Requirements</h4><p>Wireshark软件。</p><h4 id="3-Steps"><a href="#3-Steps" class="headerlink" title="3 Steps"></a>3 Steps</h4><h5 id="Step-1-Fetch-a-Trace"><a href="#Step-1-Fetch-a-Trace" class="headerlink" title="Step 1: Fetch a Trace"></a>Step 1: Fetch a Trace</h5><p>直接打开附件里的”trace-80211.pcap”来进行探究。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130225233978.png" alt="image-20221130225233978"></p><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>首先，我们将研究802.11帧的格式。如下图，有许多不同种类的802.11帧被捕获在了追踪中，我们可以通过info字段来分辨他们的类型，如Beacon、Data和Acknowledgement。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130225721909.png" alt="image-20221130225721909"></p><p>我们选中一个数据帧进行查看：</p><p><img src="/2022/12/29/CNLab4-2/image-20221130230045230.png" alt="image-20221130230045230"></p><ul><li><p>“Frame”是由Wireshark添加的记录，包含了帧的时间和长度信息等。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130231545659.png" alt="image-20221130231545659"></p></li><li><p>“Radiotap”也是Wireshark添加的记录，用于捕获物理层参数，如信号的强度和调制。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130231602103.png" alt="image-20221130231602103"></p></li><li><p>“IEEE 802.11”是802.11数据帧的位。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130231613913.png" alt="image-20221130231613913"></p></li><li><p>“Data”是包含帧有效载荷数据的记录，即具有诸如LLC、IP包等更高层协议的数据。或者，可以看到更高层的协议本身。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130231636337.png" alt="image-20221130231636337"></p></li></ul><p>接下来我们将重点探究”IEEE 802.11”中的内容。</p><ul><li><p>“Frame Control”编码帧的类型和子类型。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234650774.png" alt="image-20221130234650774"></p></li><li><p>“Duration”告诉计算机作为交换的一部分的附加数据包在无线媒体上需要多长时间。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234709140.png" alt="image-20221130234709140"></p></li><li><p>“Destination address”和”Source address”（顺序取决于数据帧的具体内容）这些地址字段标识了数据包的发送者和应接收者。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234849051.png" alt="image-20221130234849051"></p></li><li><p>“BSS Id”是无线接入点的地址。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234907719.png" alt="image-20221130234907719"></p></li><li><p>“Fragment number”和”Sequence number”这些字段为重组和重传的帧编号，序号随着每一次新的传输而递增。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234929032.png" alt="image-20221130234929032"></p></li><li><p>“Frame check sequence”是帧上的循环冗余校验码。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234939063.png" alt="image-20221130234939063"></p></li><li><p>在帧有效负载被加密的情况下，还可能有一个WEP或WPA2字段，其中包含安全参数。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130234948154.png" alt="image-20221130234948154"></p></li></ul><p>最后，我们再重点探究一下”Frame Control”字段的详细内容。</p><p><img src="/2022/12/29/CNLab4-2/image-20221130235557521.png" alt="image-20221130235557521"></p><ul><li>“Version”是版本号，目前为0（三种类型的帧统一，均为0）。</li><li>“Type”和”Subtype”指定帧的类型。</li><li>“DS status”中包含了”To DS”和”From DS”的值：如果帧从计算机通过AP发送至有线网络，则将”To DS”置为1；如果帧从有线网络通过AP发送至计算机，则将”From DS”置为1。</li><li>“More Fragments”描述了消息中是否有更多的帧。</li><li>“Retry”描述了帧是否重传。</li><li>“PWR MGT”意为”Power management”，设置了发送方在传输后是否进入省电休眠状态。</li><li>“More Data”描述发送端是否有更多的帧要发送。</li><li>“Protected”描述了帧是否用WEP&#x2F;WPA2加密。</li><li>“+HTC&#x2F;Order”描述了接收端是否必须保持帧的顺序。</li></ul><h5 id="Step-3-802-11-Physical-Layer"><a href="#Step-3-802-11-Physical-Layer" class="headerlink" title="Step 3: 802.11 Physical Layer"></a>Step 3: 802.11 Physical Layer</h5><p>现在我们已经对802.11数据帧有了一些了解，接下来我们将从物理层开始研究无线系统的其他部分。在最低层，发送和接收消息都与接收信号的频带、调制、信噪比有关，我们可以在Radiotap中的信息查看所有这些元素。</p><p><em>Q: What is the channel frequency?</em></p><p><em>A：展开”Radiotap Header”，即可查看”Channel frequency”的值。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201004342137.png" alt="image-20221201004342137"></p><p>要查看调制，我们可以观察数据速率值，要查看信噪比，我们可以观察SSI信号值，SSI信号值通常被称为RSSI(接收信号强度指示)。要查看这些字段，首先必须向主显示添加新列，步骤如下：</p><ol><li><p>按”编辑-首选项-外观-列“的顺序依次点击以进入列显示定义面板。</p></li><li><p>点击左下角”+”以添加新的显示列。</p></li><li><p>将”Title”修改为”RSSI”，类型选择”IEEE 802.11 RSSI”。</p></li><li><p>再添加一个新的显示列，将”Title”修改为”Rate”，类型选择”IEEE 802.11 TX rate”，然后选择”OK”完成添加。</p><p><img src="/2022/12/29/CNLab4-2/image-20221201005949990.png" alt="image-20221201005949990"></p></li></ol><p>我们返回主页面，可以看到”RSSI”列和”Rate”列已成功添加。</p><p><img src="/2022/12/29/CNLab4-2/image-20221201011138673.png" alt="image-20221201011138673"></p><p>在”Rate”列，我们可以看到各种各样的速率。也就是说，与有线以太网的帧以固定速率发送(经过以太网类型的协商)不同，无线速率根据计算机的条件和能力而变化。</p><p><em>Q: What rates are used? Give an ordered list of rates from lowest to highest.</em></p><p><em>A：点击”Rate”列，将帧按速率值从小到大的顺序进行排列，可以看到速率分别为1、6、12、18、24、38、48和54mbps，下面截取了部分速率区段。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201012040044.png" alt="image-20221201012040044"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201012115175.png" alt="image-20221201012115175"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201012021756.png" alt="image-20221201012021756"></p><p>在”RSSI”列，我们可以看到各种各样的RSSI值，如“-60 dBm”。RSSI是在对数刻度上测量的，其中0 dBm表示1兆瓦的功率，每+10表示大10倍，每-10表示小10倍。因此-60 dBm意味着 $10^{-9}$ 瓦，即1兆瓦的百万分之一，是非常小的功率。</p><p>信噪比是相对于噪声水平的信号水平，如下图中，信号水平为-60 dBm，噪声水平为-90 dBm，这意味着信号水平比噪声水平大1000倍，那么信噪比就为30 dB。</p><p><img src="/2022/12/29/CNLab4-2/image-20221201013239069.png" alt="image-20221201013239069"></p><p><em>Q: What is the range of RSSI and hence variation in SNRs in the trace? Give this as the strongest and  weakest RSSI and the dB difference between them.</em></p><p><em>A：点击”RSSI”列，将帧按RSSI值从小到大的顺序进行排列，可以看到RSSI的变化范围为-44 dBm（最强信号）到-69 dBm（最弱信号），中间相差了25分贝，前后信噪比之比约为316（$10^{2.5}≈316$）。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201014512601.png" alt="image-20221201014512601"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201014524273.png" alt="image-20221201014524273"></p><h5 id="Step-4-802-11-Link-Layer"><a href="#Step-4-802-11-Link-Layer" class="headerlink" title="Step 4: 802.11 Link Layer"></a>Step 4: 802.11 Link Layer</h5><p>在”统计”菜单下，选择”会话”，然后勾选”IEEE 802.11”。</p><p><img src="/2022/12/29/CNLab4-2/image-20221201214202951.png" alt="image-20221201214202951"></p><p>转到”IEEE 802.11”栏，我们将看到如下图所示的窗口，其中列出了每对正在通信的计算机。</p><p><img src="/2022/12/29/CNLab4-2/image-20221201214411420.png" alt="image-20221201214411420"></p><p>大部分的活动都是在相对较小的部分对话中。低活动会话是由于来自空闲计算机的后台流量，以及偶尔从相邻无线网络捕获的少量包。BSS ID值标识一个AP。</p><p><em>Q: What is the BSS ID used by the most active wireless conversations? A BSS ID value identifies an  AP, so this BSS ID identifies the most active AP, presumably the AP we are monitoring.</em> </p><p><em>A：为了找到最活跃的无线会话使用的BSS ID，我们可以通过单击列标题对信息进行排序，可以发现，最活跃的AP的BSS ID是00:16:b6:e3:e9:8f。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201215503765.png" alt="image-20221201215503765"></p><p>我们可以在”应用显示过滤器”处输入表达式”wlan.fc.type=&#x3D;”data frame””或”wlan.fc.type=&#x3D;2”来只查看数据帧。</p><p><img src="/2022/12/29/CNLab4-2/image-20221201220113563.png" alt="image-20221201220113563"></p><p><em>Q: How many Data frames are in the trace, and what is the most common subtype of Data frame?</em></p><p><em>A：我们可以从右下角看到当前显示帧的总数为1783，而当前显示的帧正是我们筛选得到的数据帧，所以数据帧的总数为1783。依次查看各帧的详细信息可以发现，数据帧最常见的子类型是”Data”。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201221004626.png" alt="image-20221201221004626"></p><p>通过更改筛选表达式来对Control (Type 1)和Management (Type 0)帧执行相同的操作。</p><p><em>Q: How many Control frames are in the trace, and what is the most common subtype?</em> </p><p><em>A：用跟之前同样的方法，我们可以得到控制帧的总数为1391。依次查看各帧的详细信息可以发现，控制帧最常见的子类型是”Acknowledgement”。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201221930338.png" alt="image-20221201221930338"></p><p><em>Q: How many Management frames are in the trace, and what is the most common subtype?</em></p><p><em>A：同理，我们也可以得到管理帧的总数为557。依次查看各帧的详细信息可以发现，管理帧最常见的子类型是”Beacon frame”。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201222144297.png" alt="image-20221201222144297"></p><p><em>Q: List in the order they are sent the IEEE 802.11 fields in an Acknowledgement frame and their  lengths in bytes. Do not break down the Frame Control field into subfields, as we have already  looked at these details.</em></p><p><em>A：如果我们检查一个”Acknowledgement”帧的IEEE 802.11记录，我们应该看到它与数据帧相比字段很少，例如，只有一个地址，而且它非常短。这些字段分别是帧控制(2个字节)、持续时间(2个字节)、接收地址(6个字节)和帧检查序列(4个字节)。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201222740747.png" alt="image-20221201222740747"></p><p>无线传输不像有线传输那样高度可靠，但无线误差率不会很大，否则会浪费大量的介质。我们可以通过估计重传率或检查有多少帧的重试位设置在了帧控制字段（这个位表示一个帧是原始帧的重传）来估算无线误差率。</p><p>我们可以通过使用过滤器表达式来查找原始数据帧和重传数据帧的数量。例如，“wlan.fc.type =&#x3D;2 &amp;&amp; wlan.fc.retry&#x3D;&#x3D;0”将找到原始数据帧。</p><p><em>Q: Give an estimate of the retransmission rate as the number of retransmissions over the number of  original transmissions. Show your calculation.</em></p><p><em>A：在应用显示过滤器处输入“wlan.fc.type =&#x3D;2 &amp;&amp; wlan.fc.retry&#x3D;&#x3D;0”来筛选原始数据帧，可以发现其个数为1430；输入“wlan.fc.type =&#x3D;2 &amp;&amp; wlan.fc.retry=&#x3D;1”来筛选重传数据帧，可以发现其个数为353。由此可以估计重传率为24.69%（353&#x2F;1430≈0.24685）。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201223909438.png" alt="image-20221201223909438"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201223955873.png" alt="image-20221201223955873"></p><p>最后，我们将研究电源管理。越来越多的802.11客户端设备在完成发送或接收流量时使用电源管理功能进入低功耗休眠模式。准备休眠的客户端会在帧控制字段中设置电源管理标志，我们可以使用过滤器表达式”wlan.fc.pwrmgt=&#x3D;1”来搜索表明客户端将要休眠的帧。我们只需要考虑从客户端到AP的帧的省电行为，因为来自AP的帧并不表示客户端将进入睡眠状态，这些帧将有”to DS”标志设置(“wlan.fc.tods&#x3D;&#x3D;1”)。要搜索这两个条件，可以使用“&amp;&amp;”或“and”组合筛选器表达式。</p><p><em>Q: What fraction of the frames sent to the AP signal that the client is powering down?</em></p><p><em>A：依次用”wlan.fc.tods=&#x3D;1”和”wlan.fc.pwrmgt=&#x3D;1 and wlan.fc.tods&#x3D;&#x3D;1”筛选后可以发现，发送到AP的帧共822个，其中有16帧设置了电源管理标志，比例约为1.95％(16&#x2F;822≈0.01946)。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201225156607.png" alt="image-20221201225156607"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201224940792.png" alt="image-20221201224940792"></p><h5 id="Step-5-802-11-Management"><a href="#Step-5-802-11-Management" class="headerlink" title="Step 5: 802.11 Management"></a>Step 5: 802.11 Management</h5><p>接下来，我们将研究几种类型的管理帧。</p><h6 id="Beacon-Frames"><a href="#Beacon-Frames" class="headerlink" title="Beacon Frames"></a>Beacon Frames</h6><p>选择BSS ID为Step 4中的主AP的”Beacon Frame”。我们将看到，在一些固定的参数之后，它有一系列带标记的参数，这些参数列出了AP的功能。这些参数包括AP的SSID名称(与BSS ID相匹配的文本字符串)、它支持的数据速率以及它所运行的通道。</p><p><em>Q: What is the SSID of the main AP? This is one of the tagged parameters in the Beacon frame.</em></p><p><em>A：如下图，主AP的SSID为“djw”。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201231341794.png" alt="image-20221201231341794"></p><p><em>Q: How often are Beacon frames sent for the main AP? You may find the Beacon interval given in the Beacon frame itself, or change the Time display to be show the interval since the last frame.  (Under View, select Time Display Format, and “Seconds Since Previous Displayed Packet”.)</em></p><p><em>A：如图，时间间隔为0.1024秒，约为10次&#x2F;秒。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201231717657.png" alt="image-20221201231717657"></p><p><em>Q: What data rates does the main AP support? The rates are listed under tagged parameters.</em></p><p><em>A：如图，支持的速率为1、2、5.5、6、9、11、12、18、24、36、48、54 Mbps（其中，1、2、5.5、11Mbps速率标记为“B”，这意味着它们是802.11b遗留速率而不是802.11g速率）。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201232115714.png" alt="image-20221201232115714"></p><p><em>Q: What rate is the Beacon frame transmission? The answer to this question will be found on the  Radiotap header, or more conveniently displayed in the column you added in an earlier step.</em></p><p><em>A：可以从Radiotap报头中找到”Beacon frame”传输速率，如下图，为1.0 Mb&#x2F;s。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201232405366.png" alt="image-20221201232405366"></p><h6 id="Association"><a href="#Association" class="headerlink" title="Association"></a>Association</h6><p>一旦计算机通过信标或其他方式了解到AP，它必须与AP关联，并可能在使用无线网络之前对自己进行身份验证。我们将看到计算机向AP发送关联请求，直到它得到确认。如果关联成功，那么AP将返回一个关联响应，计算机将确认该响应。</p><p><em>Q: What are the Type and Subtype values of Association Request &#x2F; Association Response frames?</em></p><p><em>A：依次查看类型为”Association …”的管理帧，可以得到关联请求&#x2F;关联响应帧的类型和子类型值分别为0x0000和0x0001。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201233301043.png" alt="image-20221201233301043"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201233344648.png" alt="image-20221201233344648"></p><h6 id="Probe-Request-x2F-Response"><a href="#Probe-Request-x2F-Response" class="headerlink" title="Probe Request&#x2F;Response"></a>Probe Request&#x2F;Response</h6><p>最后，我们来简要了解探测帧。计算机可以探测特定的AP，而不是等待从信标处了解AP。探测请求(Probe Request)由计算机发送，用于测试具有特定SSID的AP是否在附近。如果被寻找的AP在附近，那么它将用探测响应进行回复。对于计算机来说，发送探测请求的无线网络是很常见的，它们以前用来加快连接到已知网络的速度。</p><p><em>Q: What are the Type and Subtype values for the Probe Request &#x2F; Probe Response frames?</em></p><p><em>A：依次查看类型为”Probe …”的管理帧，可以得到关联请求&#x2F;关联响应帧的类型和子类型值分别为0x0004和0x0005。</em></p><p><img src="/2022/12/29/CNLab4-2/image-20221201233856165.png" alt="image-20221201233856165"></p><p><img src="/2022/12/29/CNLab4-2/image-20221201233925568.png" alt="image-20221201233925568"></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab4-1 Wireshark-ethernet</title>
    <link href="/2022/12/29/CNLab4-1/"/>
    <url>/2022/12/29/CNLab4-1/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab4-1-Ethernet"><a href="#Lab4-1-Ethernet" class="headerlink" title="Lab4-1 Ethernet"></a>Lab4-1 Ethernet</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>了解以太网帧的详细信息。</p><h4 id="2-Requirements"><a href="#2-Requirements" class="headerlink" title="2 Requirements"></a>2 Requirements</h4><p>除Wireshark外，本实验要求能使用ping命令。</p><h4 id="3-Steps"><a href="#3-Steps" class="headerlink" title="3 Steps"></a>3 Steps</h4><h5 id="Step-1-Capture-a-Trace"><a href="#Step-1-Capture-a-Trace" class="headerlink" title="Step 1: Capture a Trace"></a>Step 1: Capture a Trace</h5><ol><li><p>选择一个远程web服务器或其他公共可达的Internet主机，使用ping发送一些ping消息，并检查它是否发送应答。如下图，这里选择了“ping <a href="http://www.baidu.com”./">www.baidu.com”。</a></p><p><img src="/2022/12/29/CNLab4-1/image-20221129103913595.png" alt="image-20221129103913595"></p></li><li><p>启动Wireshark，用”icmp“过滤器开始抓包，并在选项窗口里勾选”Resolve MAC address“，这样可以转换以太网(MAC)地址以提供供应商信息。取消勾选“混杂”，混杂模式对于在广播网络上窃听发送到&#x2F;来自其他计算机的数据包时很有用，但在本实验中我们只想记录发送到&#x2F;从本计算机发出的数据包。</p><p><img src="/2022/12/29/CNLab4-1/image-20221129114019893.png" alt="image-20221129114019893"></p><p><img src="/2022/12/29/CNLab4-1/image-20221129114030347.png" alt="image-20221129114030347"></p></li><li><p>抓包开始后，重复上面的ping命令，这样数据包就会被Wireshark记录下来。</p></li><li><p>待ping命令执行完成后，返回Wireshark并停止抓包，得到的结果如下图。</p><p><img src="/2022/12/29/CNLab4-1/image-20221129114503631.png" alt="image-20221129114503631"></p></li></ol><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>选中数据包并查看其结构的详细信息和组成包的字节，如下图，可以看到开了MAC地址解析后，在MAC的源地址和目的地址都有一层解析。</p><p><img src="/2022/12/29/CNLab4-1/image-20221129114716848.png" alt="image-20221129114716848"></p><h5 id="Step-3-Ethernet-Frame-Structure"><a href="#Step-3-Ethernet-Frame-Structure" class="headerlink" title="Step 3: Ethernet Frame Structure"></a>Step 3: Ethernet Frame Structure</h5><p><em>To show your understanding of the Ethernet frame format, draw a figure of the ping message that shows the position and size in bytes of the Ethernet header fields.</em></p><table><thead><tr><th>Preamble</th><th>SFD</th><th>Destination Address</th><th>Source Address</th><th>Length&#x2F;Type</th><th>DATA</th><th>Frame Check Sequence</th></tr></thead><tbody><tr><td>7 Byte</td><td>1 Byte</td><td>6 Byte</td><td>6 Byte</td><td>2 Byte</td><td>46~1500 Byte</td><td>4 Byte</td></tr></tbody></table><h5 id="Step-4-Scope-of-Ethernet-Addresses"><a href="#Step-4-Scope-of-Ethernet-Addresses" class="headerlink" title="Step 4: Scope of Ethernet Addresses"></a>Step 4: Scope of Ethernet Addresses</h5><p>每个以太网帧都携带一个源地址和目的地址，其中一个地址就是本地电脑地址。它是发送帧的源，接收帧的目的地，那么另一个地址是什么？当我们 ping 一个远程Internet服务器的时候，我们输入的是域名，经过DNS解析后得到IP地址，我们与目的服务器必然不是直接链接的关系，这中间发生了什么呢？</p><p><em>Draw a figure that shows the relative positions of your computer, the router, and the remote server. Label your computer and the router with their Ethernet addresses. Label your computer and the remote  server with their IP addresses. Show where the Ethernet and the rest of the Internet fit on the drawing.</em></p><p><img src="/2022/12/29/CNLab4-1/image-20221130172601068.png" alt="image-20221130172601068"></p><p><img src="/2022/12/29/CNLab4-1/image-20221130205448670.png" alt="image-20221130205448670"></p><h5 id="Step-5-Broadcast-Frames"><a href="#Step-5-Broadcast-Frames" class="headerlink" title="Step 5: Broadcast Frames"></a>Step 5: Broadcast Frames</h5><p>接下来的部分，可以直接用附件里的”trace-ethernet.pcap”来进行探究。</p><p><em>1. What is the broadcast Ethernet address, written in standard form as Wireshark displays it?</em></p><p>如图可知，地址为 FF:FF:FF:FF:FF:FF 。</p><p><img src="/2022/12/29/CNLab4-1/image-20221130210423289.png" alt="image-20221130210423289"></p><p><em>2. Which bit of the Ethernet address is used to determine whether it is unicast or multicast&#x2F;broadcast?</em></p><p>第8个bit（第一个字节的最低位）。</p><p>如果该位为0，则是某台设备的MAC地址，即单播地址；如果该位为1，则是多播地址（组播+广播&#x3D;多播）。</p><p><img src="/2022/12/29/CNLab4-1/image-20221130211047548.png" alt="image-20221130211047548"></p><h4 id="4-Explore-on-your-own-IEEE-802-3"><a href="#4-Explore-on-your-own-IEEE-802-3" class="headerlink" title="4 Explore on your own (IEEE 802.3)"></a>4 Explore on your own (IEEE 802.3)</h4><p><em>1. How long are the combined IEEE 802.3 and LLC headers compared to the DIX Ethernet headers? You can use Wireshark to work this out. Note that the Trailer&#x2F;Padding and Checksum may be  shown as part of the header, but they come at the end of the frame.</em></p><p>IEEE 802.3与DIX Ethernet一样，报头长度为14 bytes。LLC加入了3 bytes的长度，总长度为17 bytes。</p><p><img src="/2022/12/29/CNLab4-1/image-20221130211741035.png" alt="image-20221130211741035"></p><p><img src="/2022/12/29/CNLab4-1/image-20221130211758296.png" alt="image-20221130211758296"></p><p><em>2. How does the receiving computer know whether the frame is DIX Ethernet or IEEE 802.3? Hint:  you may need to both use Wireshark to look at packet examples and read your text near where the Ethernet formats are described.</em> </p><p>“DIX Ethernet Type”字段和“IEEE 802.3 Length”字段的位置相同。如果该值小于Ox600(1536)，则将其解释为Length值。如果该值大于Ox600(1536)，则将其解释为Type值。</p><p><em>3. If IEEE 802.3 has no Type field, then how is the next higher layer determined? Use Wireshark to  look for the demultiplexing key.</em></p><p>IEEE 802.3在IEEE 802.3报头之后立即添加LLC报头，以传递下一层协议，这从上面的两张图中也能看出来。</p><p>p.s. LLC使用一个称为DSAP的初始字节，而不是Type字段中的两个字节。</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab1-2 Wireshark-protocal layers</title>
    <link href="/2022/12/29/CNLab1-2/"/>
    <url>/2022/12/29/CNLab1-2/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab1-2-Protocol-Layers"><a href="#Lab1-2-Protocol-Layers" class="headerlink" title="Lab1-2 Protocol Layers"></a>Lab1-2 Protocol Layers</h2><h4 id="1-Objective"><a href="#1-Objective" class="headerlink" title="1 Objective"></a>1 Objective</h4><p>了解如何在数据包中表示协议和分层。</p><h4 id="2-Requirements"><a href="#2-Requirements" class="headerlink" title="2 Requirements"></a>2 Requirements</h4><p>实验指导书中该部分分为Wireshark软件安装和wget（或curl）安装，Wireshark安装之前已经记录过了，这里就只写wget的获取了。</p><h5 id="2-1-下载安装wget"><a href="#2-1-下载安装wget" class="headerlink" title="2.1 下载安装wget"></a>2.1 下载安装wget</h5><p>前往<a href="https://eternallybored.org/misc/wget/">GNU Wget 1.21.3 for Windows (eternallybored.org)</a>下载wget，这里选择了1.21.3–64bit–ZIP。</p><h5 id="2-2-配置环境变量"><a href="#2-2-配置环境变量" class="headerlink" title="2.2 配置环境变量"></a>2.2 配置环境变量</h5><p>将文件解压到的路径添加至环境变量。</p><h5 id="2-3-测试"><a href="#2-3-测试" class="headerlink" title="2.3 测试"></a>2.3 测试</h5><p>若成功显示wget版本即说明安装成功。</p><p><img src="/2022/12/29/CNLab1-2/image-20221128221711788.png" alt="image-20221128221711788"></p><h4 id="3-Steps"><a href="#3-Steps" class="headerlink" title="3 Steps"></a>3 Steps</h4><h5 id="Step-1-Capture-a-Trace"><a href="#Step-1-Capture-a-Trace" class="headerlink" title="Step 1: Capture a Trace"></a>Step 1: Capture a Trace</h5><ol><li><p>使用wget获取输入的URL的资源，如果状态代码为”200 OK“则说明获取成功，如下图。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129034710216.png" alt="image-20221129034710216"></p></li><li><p>关闭不必要的浏览器选项卡和窗口，通过最小化浏览器活动来阻止计算机获取不必要的web内容，避免在追踪过程中的偶然的流量。</p></li><li><p>启动Wireshark，用”tcp port 80“过滤器开始抓包，并在选项窗口里勾选”Resolve network names“。这个过滤器将只记录标准的网络流量，而不记录计算机可能发送的其他类型的包。勾选的作用是将把发送和接收数据包的计算机的地址转换为名称，这将帮助我们识别数据包是发送到计算机的还是计算机发送出去的。</p><p><img src="/2022/12/29/CNLab1-2/image-20221128223758803.png" alt="image-20221128223758803"></p><p><img src="/2022/12/29/CNLab1-2/image-20221128223906894.png" alt="image-20221128223906894"></p></li><li><p>抓包开始时，使用wget重复web获取，这次的报文就会在传输过程中会被Wireshark记录下来。</p></li><li><p>获取成功后，返回Wireshark并停止抓包。如果成功了的话，Wireshark窗口将显示多个包。捕获的包的个数取决于web页面的大小，通常为20到100个，至少有8个。如下图，本次共抓取了11个（正常包有8个）。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129034513536.png" alt="image-20221129034513536"></p></li></ol><h5 id="Step-2-Inspect-the-Trace"><a href="#Step-2-Inspect-the-Trace" class="headerlink" title="Step 2: Inspect the Trace"></a>Step 2: Inspect the Trace</h5><p>我们可以选中一个数据包来查看它的协议层。这里我们选择一个”Protocol“（协议）列为”HTTP“且”Info“（信息）列为”GET“开头的数据包，可以看到共四层协议，分别为以太网、IP(IPv4)、TCP和HTTP。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129034647595.png" alt="image-20221129034647595"></p><p>注意，顺序是从协议栈的底部向上的。这是因为当数据包沿着堆栈向下传递时，底层协议的头信息被添加到来自上层协议的信息前面。也就是说，下层协议在“线上”数据包中首先出现。</p><p>接下来找到对应从服务器到本机的响应的另一个”HTTP“数据包，这个包的Info字段中应该有“200 OK”，表示获取成功。与HTTP GET包对比，可以看到其有两个额外的部分，如下图所示。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129034803774.png" alt="image-20221129034803774"></p><p>第一个额外的部分写着“[2 Reassembled TCP Segments (2497 bytes): #6(1452), #7(1045)]”，它是关于如何将从服务器发往本机的数据包按顺序组合起来的（因为web响应是通过发送一系列数据包到计算机来实现的，标记为HTTP的数据包是web响应的最后一个数据包）。虽然这些数据包携带着部分HTTP相应，但当前他们每一个都显示有”TCP“。只有最后的包显示为具有HTTP协议时，它们才被组合成一个完整的 HTTP 响应。</p><p>第二个额外的部分写着”Line-based text data: text&#x2F;html (2 lines)“，它描述的是所获取的网页的内容。这不是一个真正的协议，它是Wireshark正在生成的包内容的描述，以帮助我们理解网络流量。</p><h5 id="Step-3-Packet-Structure"><a href="#Step-3-Packet-Structure" class="headerlink" title="Step 3: Packet Structure"></a>Step 3: Packet Structure</h5><p><em>To show your understanding of packet structure, draw a figure of an HTTP GET packet that shows the  position and size in bytes of the TCP, IP and Ethernet protocol headers.</em></p><table><thead><tr><th>Ethernet</th><th>IP</th><th>TCP</th><th>HTTP</th></tr></thead><tbody><tr><td>14B</td><td>20B</td><td>20B</td><td>128B</td></tr><tr><td>Ethernet Header</td><td>Ethernet Payload</td><td>~</td><td>~</td></tr><tr><td></td><td>IP Header</td><td>IP Payload</td><td>~</td></tr><tr><td></td><td></td><td>TCP Header</td><td>TCP Payload</td></tr></tbody></table><p><img src="/2022/12/29/CNLab1-2/image-20221129041434626.png" alt="image-20221129041434626"></p><h5 id="Step-4-Protocol-Overhead"><a href="#Step-4-Protocol-Overhead" class="headerlink" title="Step 4: Protocol Overhead"></a>Step 4: Protocol Overhead</h5><p><em>Estimate the download protocol overhead, or percentage of the download bytes taken up by protocol  overhead. To do this, consider HTTP data (headers and message) to be useful data for the network to  carry, and lower layer headers (TCP, IP, and Ethernet) to be the overhead.</em></p><p>可以通过对Destination列进行排序来只查看下载方向的数据包。数据包应该以一个描述为[SYN ACK]的短TCP包开始，这是连接的开始。接下来，是较大的TCP包（大约1到1.5KB）。最后一个是HTTP包（也可能以一个短的TCP包结束，它是结束连接的一部分）。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129035044873.png" alt="image-20221129035044873"></p><p>对于每个包，我们可以检查它以Ethernet&#x2F;IP&#x2F;TCP报头的形式有多少开销，以及它在TCP有效负载中携带了多少有用的HTTP数据。</p><p>我们依次选中数据包，可以看到下载过程数据总长度为：66 + 56 + 1506 + 1099 &#x3D; 2727 bytes，HTTP数据长度为：1045 bytes，所以下载开销占比为：(2727-1045)&#x2F;2727≈61.7％。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129040200799.png" alt="image-20221129040200799"></p><p>下载协议开销很重要，它保证了数据传输的正确性和可恢复性。因为这里我们的GET请求数据包较短，所以下载协议开销较大。额外的开销部分虽然不是定长，但是基本是在一个较为确定的范围内，只要GET请求的内容包括更多的信息，只要数据包足够大，额外开销的占比就会趋近于0。</p><h5 id="Step-5-Demultiplexing-Keys"><a href="#Step-5-Demultiplexing-Keys" class="headerlink" title="Step 5: Demultiplexing Keys"></a>Step 5: Demultiplexing Keys</h5><p>解复用（Demultiplexing）：当数据包从交给上层进行处理时，需要找到正确的上层协议，这个过程就叫做解复用。</p><p>解复用键（Demultiplexing Keys）：在协议头中来指明上层协议的信息。</p><p><em>1. Which Ethernet header field is the demultiplexing key that tells it the next higher layer is IP?  What value is used in this field to indicate “IP”?</em></p><p>如图：Type；0x0800。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129041859851.png" alt="image-20221129041859851"></p><p><em>2. Which IP header field is the demultiplexing key that tells it the next higher layer is TCP? What  value is used in this field to indicate “TCP”?</em></p><p>如图：Protocol；0x06。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129041934849.png" alt="image-20221129041934849"></p><h4 id="4-Explore-on-your-own"><a href="#4-Explore-on-your-own" class="headerlink" title="4 Explore on your own"></a>4 Explore on your own</h4><p> <em>Look at a short TCP packet that carries no higher-layer data. To what entity is this packet destined? After all, if it carries no higher-layer data then it does not seem very useful to a higher layer protocol such as HTTP!</em></p><p>下图就是一个不包含更高层数据的TCP数据包。</p><p><img src="/2022/12/29/CNLab1-2/image-20221129042407851.png" alt="image-20221129042407851"></p><p>在TCP协议中，建立连接需要三次握手，结束连接需要4次挥手。这几次的数据传递均是不包括高层协议数据的，目的是为了确保连接建立的稳定和准确。</p><p><em>In a classic layered model, one message from a higher layer has a header appended by the lower  layer and becomes one new message. But this is not always the case. Above, we saw a trace in  which the web response (one HTTP message comprised of an HTTP header and an HTTP payload) was converted into multiple lower layer messages (being multiple TCP packets). Imagine  that you have drawn the packet structure (as in step 2) for the first and last TCP packet carrying  the web response. How will the drawings differ?</em> </p><p>第一个包的首部中，Connection字段的值为：keep-alive，表明后续仍有数据。最后一个包请求头中Connection字段的值为：close，表明传输结束，同时最后一个包中还会包含FIN&#x3D;1来请求关闭连接。</p><p><em>In the classic layered model described above, lower layers append headers to the messages  passed down from higher layers. How will this model change if a lower layer adds encryption?</em> </p><p>加密的目的是为了保密内容，所以加密的类型和加密密钥不能随着加密数据一同发送，而是应该在传输数据前根据加密协议进行协商确定。</p><p><em>In the classic layered model described above, lower layers append headers to the messages  passed down from higher layers. How will this model change if a lower layer adds compression?</em></p><p>压缩的目的是为了节省传输流量，所以压缩的协议可直接在下层协议头中指明，便于接收方解压缩。</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lab1-1 Wireshark_Intro_v7.0</title>
    <link href="/2022/12/29/CNLab1-1/"/>
    <url>/2022/12/29/CNLab1-1/</url>
    
    <content type="html"><![CDATA[<h2 id="Lab1-1-Getting-Started"><a href="#Lab1-1-Getting-Started" class="headerlink" title="Lab1-1 Getting Started"></a>Lab1-1 Getting Started</h2><h4 id="1-Getting-Wireshark"><a href="#1-Getting-Wireshark" class="headerlink" title="1 Getting Wireshark"></a>1 Getting Wireshark</h4><p>从 <a href="http://www.wireshark.org/download.html">http://www.wireshark.org/download.html</a> 下载并安装Wireshark。</p><h4 id="2-Running-Wireshark"><a href="#2-Running-Wireshark" class="headerlink" title="2 Running Wireshark"></a>2 Running Wireshark</h4><p>Wireshark初始界面：</p><p><img src="/2022/12/29/CNLab1-1/image-20221127193758653.png" alt="image-20221127193758653"></p><p>双击接口名称即可进入对应接口进行抓包，如进入WLAN接口：</p><p><img src="/2022/12/29/CNLab1-1/image-20221127194333009.png" alt="image-20221127194333009"></p><p>抓包界面可大致分为以下五部分：</p><p><img src="/2022/12/29/CNLab1-1/image-20221127200002502.png" alt="image-20221127200002502"></p><ol><li>命令菜单：常用的是”文件“和”捕获“菜单。“文件”菜单可以保存抓包数据，也可以打开以前的抓包数据文件，还有退出Wireshark应用程序等。“捕获”菜单可以允许我们开始或停止抓包。</li><li>数据包列表窗口：显示每一个捕获包的一行摘要，包括包号、数据包被捕获的时间、数据包的源地址和目的地址、协议类型以及数据包中包含的特定于协议的信息。</li><li>包头详细信息窗口：提供了包列表窗口中选中的包的详细信息。这些详细信息包括以太网帧(假设数据包通过以太网接口发送&#x2F;接收)和包含该数据包的IP数据报的信息。</li><li>数据包内容窗口：以ASCII和十六进制格式显示捕获帧的全部内容。</li><li>包过滤显示区域：可以在其中输入协议名或其他信息，以便过滤包列表窗口(以及包头和包内容窗口)中显示的信息。</li></ol><h4 id="3-Taking-Wireshark-for-a-Test-Run"><a href="#3-Taking-Wireshark-for-a-Test-Run" class="headerlink" title="3 Taking Wireshark for a Test Run"></a>3 Taking Wireshark for a Test Run</h4><p>试运行Wireshark来学习其使用流程。</p><ol><li><p>打开浏览器。</p></li><li><p>打开Wireshark软件。</p></li><li><p>选择“捕获”下拉菜单并选择“选项”，打开”Wireshark·捕获选项“。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127202204806.png" alt="image-20221127202204806"></p></li><li><p>选中要开始抓包的接口，然后点击”开始“。</p></li><li><p>开始抓包之后，选择“抓包”下拉菜单并选择“停止”，可以停止抓包（但是现在先不要停止抓包）。</p></li><li><p>当Wireshark正在运行时，在浏览器中打开：<a href="http://gaia.cs.umass.edu/wireshark-labs/INTRO-wireshark-filel.html%E3%80%82%E4%B8%BA%E4%BA%86%E6%98%BE%E7%A4%BA%E6%AD%A4%E9%A1%B5%E9%9D%A2%EF%BC%8C%E6%B5%8F%E8%A7%88%E5%99%A8%E5%B0%86%E5%9C%A8">http://gaia.cs.umass.edu/wireshark-labs/INTRO-wireshark-filel.html。为了显示此页面，浏览器将在</a> <em>gaia.cs.umass.edu</em> 与HTTP服务器联系，并与服务器交换HTTP消息以下载此页面。包含这些HTTP消息的以太网帧(以及通过以太网适配器的所有其他帧)将被Wireshark捕获。</p></li><li><p>在浏览器显示下面的页面后，点击停止按钮，现在可以在已捕获包列表中看到通过这个网络接口的所有的数据包。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127203421287.png" alt="image-20221127203421287"></p></li><li><p>在应用显示过滤器窗口中输入“http”，然后选择Apply(在输入“http”的右侧)。这将导致在包列表窗口中只显示HTTP消息。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127203915269.png" alt="image-20221127203915269"></p></li><li><p>查看HTTP GET信息。当选择HTTP GET消息时，将在报文报头窗口中显示以太网帧、IP数据报、TCP段和HTTP消息报头信息。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127204445952.png" alt="image-20221127204445952"></p></li><li><p>退出Wireshark。</p></li></ol><h4 id="4-What-to-hand-in（Questions）"><a href="#4-What-to-hand-in（Questions）" class="headerlink" title="4 What to hand in（Questions）"></a>4 What to hand in（Questions）</h4><p><em>1. List 3 different protocols that appear in the protocol column in the unfiltered  packet-listing window in step 7 above.</em></p><p>如下图，OICQ，TCP，UDP。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127204731876.png" alt="image-20221127204731876"></p><p><em>2.  How long did it take from when the HTTP GET message was sent until the HTTP  OK reply was received? (By default, the value of the Time column in the packet-listing window is the amount of time, in seconds, since Wireshark tracing began.  To display the Time field in time-of-day format, select the Wireshark View pull  down menu, then select Time Display Format, then select Time-of-day.)</em></p><p>如下图，约为0.241秒。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127205727136.png" alt="image-20221127205727136"></p><p><em>3. What is the Internet address of the gaia.cs.umass.edu (also known as wwwnet.cs.umass.edu)? What is the Internet address of your computer?</em></p><p>如图，<em>gaia.cs.umass.edu</em> 的地址为128.119.245.12，本机地址为172.25.192.244。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127205827144.png" alt="image-20221127205827144"></p><p><em>4. Print the two HTTP messages (GET and OK) referred to in question 2 above. To do so, select Print from the Wireshark File command menu, and select the “Selected Packet Only” and “Print as displayed” radial buttons, and then click OK.</em></p><p>如果，点击”确定“即可打印。</p><p><img src="/2022/12/29/CNLab1-1/image-20221127210357704.png" alt="image-20221127210357704"></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络实验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>Wireshark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一篇博客</title>
    <link href="/2022/12/29/testblog/"/>
    <url>/2022/12/29/testblog/</url>
    
    <content type="html"><![CDATA[<h4 id="似乎有点晚"><a href="#似乎有点晚" class="headerlink" title="似乎有点晚"></a>似乎有点晚</h4><p>建立一个博客来记录学习生活及平时的心理历程等。</p><p>这里是公式测试</p><p>$a^b$<br>$$<br>x_i^y<br>$$<br>这里是图片测试</p><p><img src="/2022/12/29/testblog/f0.jpg" alt="测试图片"></p><p>这里是代码测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;hello world&quot;</span>)<br></code></pre></td></tr></table></figure><p>这里是表格测试</p><table><thead><tr><th align="center">A</th><th align="center">B</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">1</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>test</category>
      
    </categories>
    
    
    <tags>
      
      <tag>testtag</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
